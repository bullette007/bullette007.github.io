{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32f6d17",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Basics\" data-toc-modified-id=\"Basics-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Basics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Custom-sensor-plugins-for-Mitsuba-3\" data-toc-modified-id=\"Custom-sensor-plugins-for-Mitsuba-3-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Custom sensor plugins for Mitsuba 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Install-Mitsuba-3\" data-toc-modified-id=\"Install-Mitsuba-3-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Install Mitsuba 3</a></span></li><li><span><a href=\"#Plugin-for-pinhole-camera\" data-toc-modified-id=\"Plugin-for-pinhole-camera-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Plugin for pinhole camera</a></span></li><li><span><a href=\"#Plugin-for-thin-lens-camera\" data-toc-modified-id=\"Plugin-for-thin-lens-camera-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Plugin for thin lens camera</a></span></li><li><span><a href=\"#Plugin-for-telecentric-camera\" data-toc-modified-id=\"Plugin-for-telecentric-camera-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Plugin for telecentric camera</a></span></li></ul></li><li><span><a href=\"#Custom-emitter-plugins-for-Mitsuba\" data-toc-modified-id=\"Custom-emitter-plugins-for-Mitsuba-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Custom emitter plugins for Mitsuba</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plugin-for-telecentric-illumination\" data-toc-modified-id=\"Plugin-for-telecentric-illumination-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Plugin for telecentric illumination</a></span></li></ul></li><li><span><a href=\"#Fourier-transform\" data-toc-modified-id=\"Fourier-transform-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Fourier transform</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convolution-in-the-Fourier-domain\" data-toc-modified-id=\"Convolution-in-the-Fourier-domain-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Convolution in the Fourier domain</a></span></li><li><span><a href=\"#Hybrid-images\" data-toc-modified-id=\"Hybrid-images-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Hybrid images</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e29d1b",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f7987",
   "metadata": {},
   "source": [
    "## Custom sensor plugins for Mitsuba 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1842ad1",
   "metadata": {},
   "source": [
    "The [Mitsuba renderer](https://www.mitsuba-renderer.org/) is a photorealistic renderer in the style of the famous *Physically Based Renderer (PBRT)*, which can be extended by customized add ons, so-called plugins. This allows novel sensor concepts or light sources to  be added to Mitsuba. \n",
    "\n",
    "The Mitsuba renderer consists of five main components whose interaction is illustrated in the following Figure:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea506083",
   "metadata": {},
   "source": [
    "<img src=\"figures/ex1/RendererPrinzip.svg\" style=\"max-height:40vh\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd647a",
   "metadata": {},
   "source": [
    "Every scene that should be rendered with Mitsuba consists of at least a sensor component, such as a camera, and a light emitter. Further objects can be composed out of so-called shapes or they can be added by means of their CAD model.\n",
    "\n",
    "To synthesize the sought camera image, a classical ray tracing algorithm is employed: The renderer component generates two-dimensional continuous sensor samples $\\mathbf{p}^\\mathrm{b}$ according to a certain sampling strategy and, if requested by the sensor plugin, additional aperture samples $\\mathbf{p}^\\mathrm{a}$ and passes them to the sensor plugin. \n",
    "For example, an aperture sample is needed by plugins modeling conventional cameras (e.g., the thin lens camera model), where every pixel integrates incident light rays coming from multiple directions. The sensor calculates the ray of sight corresponding to the received spatial sample $\\mathbf{p}^\\mathrm{b}$ and, if applicable, the aperture sample $\\mathbf{p}^\\mathrm{a}$ according to its sensor model. Rays of sight are defined as tuples $(\\mathbf{o},\\mathbf{d})$ of a point of origin $\\mathbf{o}$ and the direction of propagation $\\mathbf{d}$. The ray of sight is passed back to the renderer, which starts tracing the ray through the modeled scene. The ray might hit the surface of an object, get absorbed, reflected or refracted and might receive new directions of propagation. The tracing is continued until no further intersection happens (i.e., the ray directs into empty space), a fixed number of intersections is exceeded or a light source has been reached. In the latter case, the reached light source component is queried for its radiance $R$ with respect to the current ray of sight. The renderer propagates the received radiance $R$ back along the whole optical path of the traced ray by taking all optical effects that occur along the way and the reflectance characteristics of all involved surfaces into account. The resulting radiance $R'$ and the current sensor sample $\\mathbf{p}^\\mathrm{b}$ are passed to the film component which successively aggregates the received radiances and finally creates the output image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b26046",
   "metadata": {},
   "source": [
    "In the following exercises, several plugins for Mitsuba will be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcfb1f",
   "metadata": {},
   "source": [
    "### Install Mitsuba 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e2ce49",
   "metadata": {},
   "source": [
    "Run the following command in a >= Python 3.8-environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f644cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mitsuba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf678c4d",
   "metadata": {},
   "source": [
    "Import mitsuba, drjit and matplotlib and set the default mitsuba variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = \"scalar_rgb\"\n",
    "#variant = \"cuda_ad_rgb\"\n",
    "#variant = \"llvm_ad_rgb\"\n",
    "\n",
    "import os as os\n",
    "os.environ[\"MI_DEFAULT_VARIANT\"] = variant\n",
    "\n",
    "import mitsuba as mi\n",
    "import drjit as dr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mi.set_variant(variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12524745",
   "metadata": {},
   "source": [
    "### Plugin for pinhole camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3c02d",
   "metadata": {},
   "source": [
    "Implement a class for the pinhole camera.<br> Fill in the correct code at the marked gap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d1a8e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b7735",
   "metadata": {},
   "source": [
    "Since the mitsuba documentation is insufficient, here is a description of the signature of the relevant function `sample_ray_differential`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb6d2d",
   "metadata": {},
   "source": [
    "`time`: Not needed, for dynamic scenes only.<br>\n",
    "`sample1`: 1D-sample for wavelenght. Not needed, for high spectral resolution only.<br>\n",
    "`sample2`: 2D-sample $\\in [0,1] \\times [0,1]$ for the spatial position on the sensor / image plane.<br>\n",
    "`sample3`: 3D-sample $\\in [0,1] \\times [0,1]$ for the spatial position on the aperture plane (i.e., where the pinhole is).<br>\n",
    "`active`: Boolean denoting whether this sensor is currently active. Not needed, for multi-sensor scenarios only.<br><br>\n",
    "Returns tuple `(RayDifferential3f : rayd, Color3f : weight)`: <br>\n",
    "`rayd`: The normalized ray of sight corresponding to the provided samples, in world coordinates.<br>\n",
    "`weight`: Weight factors for the individual color channels to account for spectrally varying sensor sensitivity. Can be set to $(1.0, 1.0, 1.0)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dca95",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18a195",
   "metadata": {},
   "source": [
    "The pinhole camera is described via the parameters<br>\n",
    "`to_world`: The transformation from camera to world coordinates.<br>\n",
    "`img_dist`: The distance between the aperture plane (with the pinhole) and the sensor plane.<br>\n",
    "`sen_size`: The size of the (square) sensor plane (hence only one parameter).<br>\n",
    "`pinh_rad`: The radius of the pinhole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7579cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pinhole_sensor (mi.Sensor):\n",
    "    def __init__(self, props):\n",
    "        mi.Sensor.__init__(self, props)\n",
    "        self.to_world = props['to_world']\n",
    "        self.img_dist = props['img_dist']\n",
    "        self.sen_size = props['sen_size']\n",
    "        self.pinh_rad = props['pinh_rad']\n",
    "        self.filmsize = (self.sen_size, self.sen_size)\n",
    "            \n",
    "    def sample_ray_differential(self, time, sample1, sample2, sample3, active=True):\n",
    "        \n",
    "        #INSERT CODE HERE\n",
    "        \n",
    "        return (rayd, mi.Color3f(1.0, 1.0, 1.0))\n",
    "\n",
    "    def to_string(self):\n",
    "        return ('pinhole_sensor[\\n'\n",
    "                '    img_dist=%s,\\n'\n",
    "                '    sen_size=%s,\\n'\n",
    "                '    pinh_rad=%s,\\n'\n",
    "                ']' % (self.img_dist, self.sen_size, self.pinh_rad))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6b8b8",
   "metadata": {},
   "source": [
    "We now register the sensor so that it can be used for rendering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.register_sensor(\"pinhole_sensor\", lambda props: pinhole_sensor(props))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b9c93",
   "metadata": {},
   "source": [
    "Describe a scene with a single illuminating sphere (i.e., an area light source with the shape of a sphere) observed by a pinhole camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = mi.load_dict({\n",
    "    'type': 'scene',\n",
    "    'integrator': {\n",
    "        'type': 'path'\n",
    "    },\n",
    "\n",
    "    'sphere' : {\n",
    "        'type': 'sphere',\n",
    "        'emitter': {\n",
    "            'type': 'area',\n",
    "            'radiance': {\n",
    "            'type': 'rgb',\n",
    "            'value': 1.0,\n",
    "        },\n",
    "    },\n",
    "    'center': [0, 0, 5],\n",
    "    'radius': 2,\n",
    "        \n",
    "    },\n",
    "    'sensor': {\n",
    "        'type': 'pinhole_sensor',\n",
    "        'to_world': mi.ScalarTransform4f.look_at(origin=[0, 0, 0],\n",
    "                                                 target=[0, 0, 1],\n",
    "                                                 up=[0, 1, 0]),\n",
    "        'img_dist': 2.5,\n",
    "        'sen_size': 5.0,\n",
    "        'pinh_rad': 0.001,\n",
    "        'film': {'type': 'hdrfilm',\n",
    "      'width': 256,\n",
    "      'height': 256,\n",
    "      'rfilter': {'type': 'gaussian'},\n",
    "      'pixel_format': 'rgb',\n",
    "      'component_format': 'float32'},\n",
    "     'sampler': {'type': 'independent', 'sample_count': 8},\n",
    "    }\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc1142",
   "metadata": {},
   "source": [
    "Render the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3865562",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mi.render(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f82978",
   "metadata": {},
   "source": [
    "Display the resulting image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30e907",
   "metadata": {},
   "source": [
    "Try different values for the pinhole radius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83278ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "radi = dr.linspace(dr.scalar.ArrayXf,0.001, 1.0, 20)\n",
    "\n",
    "images = []\n",
    "\n",
    "for rad in radi:\n",
    "    scene.sensors()[0].pinh_rad = rad\n",
    "    cur_img = mi.render(scene)\n",
    "    images.append(cur_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca1179",
   "metadata": {},
   "source": [
    "Visualize those images - what do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b9a47",
   "metadata": {},
   "source": [
    "### Plugin for thin lens camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ab7db",
   "metadata": {},
   "source": [
    "Implement a class for the thin lens camera.<br> Fill in the correct code at the marked gap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e56b5",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944c770",
   "metadata": {},
   "source": [
    "The thin lens camera is described via the parameters<br>\n",
    "`to_world`: The transformation from camera to world coordinates.<br>\n",
    "`foc_len`:  The focal length of the lens. <br>\n",
    "`img_dist`: The distance between the aperture plane (with the lens) and the sensor plane.<br>\n",
    "`sen_size`: The size of the (square) sensor plane (hence only one parameter).<br>\n",
    "`lens_rad`: The radius of the lens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde275da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class thin_lens_sensor (mi.Sensor):\n",
    "    def __init__(self, props):\n",
    "        mi.Sensor.__init__(self, props)\n",
    "        self.to_world = props['to_world']\n",
    "        self.foc_len  = props['foc_len']\n",
    "        self.img_dist = props['img_dist']\n",
    "        self.sen_size = props['sen_size']\n",
    "        self.lens_rad = props['lens_rad']\n",
    "        self.filmsize = (self.sen_size, self.sen_size)\n",
    "            \n",
    "    def sample_ray_differential(self, time, sample1, sample2, sample3, active=True):\n",
    "        \n",
    "        #INSERT CODE HERE\n",
    "        \n",
    "        return (rayd, mi.Color3f(1.0, 1.0, 1.0))\n",
    "\n",
    "    \n",
    "    def to_string(self):\n",
    "        return ('thin_lens_sensor[\\n'\n",
    "                '    foc_len=%s,\\n'\n",
    "                '    img_dist=%s,\\n'\n",
    "                '    sen_size=%s,\\n'\n",
    "                '    lens_rad=%s,\\n'\n",
    "                ']' % (self.foc_len, self.img_dist, self.sen_size, self.lens_rad))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f633e7",
   "metadata": {},
   "source": [
    "We now register the sensor so that it can be used for rendering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231acf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.register_sensor(\"thin_lens_sensor\", lambda props: thin_lens_sensor(props))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be358b5",
   "metadata": {},
   "source": [
    "Describe a scene with a single illuminating sphere (i.e., an area light source with the shape of a sphere) with radius of $1$ observed by a thin lens camera.<br>\n",
    "The sphere shall be located at $\\mathbf{p}^\\mathrm{c}=(0,0,8)^\\intercal$ and shall be sharply imaged by the camera with a magnification of $V=2.0$. The sensor shall have a physical size of $10.0 \\times 10.0$ with a resolution of $100 \\times 100$ pixel.<br> Experiment with different lens radii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b30314",
   "metadata": {},
   "source": [
    "Render the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mi.render(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449350d",
   "metadata": {},
   "source": [
    "Display the resulting image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0be46a",
   "metadata": {},
   "source": [
    "### Plugin for telecentric camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64437c22",
   "metadata": {},
   "source": [
    "Implement a class for a telecentric camera.<br> Fill in the correct code at the marked gap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3169d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45412ec1",
   "metadata": {},
   "source": [
    "The telecentric camera is described via the parameters<br>\n",
    "`to_world`: The transformation from camera to world coordinates.<br>\n",
    "`foc_len`:  The focal length of the lens. <br>\n",
    "`img_dist`: The distance between the aperture plane (with the lens) and the sensor plane.<br>\n",
    "`sen_size`: The size of the (square) sensor plane (hence only one parameter).<br>\n",
    "`lens_rad`: The radius of the lens.<br>\n",
    "`stop_rad`: The radius of the open circular region of the telecentric stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d643e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class telecentric_sensor (mi.Sensor):\n",
    "    def __init__(self, props):\n",
    "        mi.Sensor.__init__(self, props)\n",
    "        self.to_world = props['to_world']\n",
    "        self.foc_len  = props['foc_len']\n",
    "        self.img_dist = props['img_dist']\n",
    "        self.sen_size = props['sen_size']\n",
    "        self.lens_rad = props['lens_rad']\n",
    "        self.stop_rad = props['stop_rad']\n",
    "        self.filmsize = (self.sen_size, self.sen_size)\n",
    "            \n",
    "    def sample_ray_differential(self, time, sample1, sample2, sample3, active=True):\n",
    "       \n",
    "        #INSERT CODE HERE\n",
    "        \n",
    "        return (rayd, mi.Color3f(weight, weight, weight))\n",
    "\n",
    "    \n",
    "    def to_string(self):\n",
    "        return ('telecentric_sensor[\\n'\n",
    "                '    foc_len=%s,\\n'\n",
    "                '    img_dist=%s,\\n'\n",
    "                '    sen_size=%s,\\n'\n",
    "                '    lens_rad=%s,\\n'\n",
    "                '    stop_rad=%s,\\n'\n",
    "                ']' % (self.foc_len, self.img_dist, self.sen_size, self.lens_rad, self.stop_rad))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a604e9",
   "metadata": {},
   "source": [
    "We now register the sensor so that it can be used for rendering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.register_sensor(\"telecentric_sensor\", lambda props: telecentric_sensor(props))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528024fc",
   "metadata": {},
   "source": [
    "Use the same scene as for the thin lens camera.<br> Experiment with different stop radii and distances of the object to the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28178613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeab6a3",
   "metadata": {},
   "source": [
    "Render the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1ec89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = mi.render(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70ef65",
   "metadata": {},
   "source": [
    "Display the resulting image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90be7b1",
   "metadata": {},
   "source": [
    "## Custom emitter plugins for Mitsuba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057bf0c",
   "metadata": {},
   "source": [
    "### Plugin for telecentric illumination "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec529654",
   "metadata": {},
   "source": [
    "We will now create a custom emitter plugin for Mitsuba.<br>\n",
    "\n",
    "The telecentric illumination is supposed to act like an area light source with the additional possibility to control the emission angle around the surface normal. It will be attached to a shape (i.e., a sphere or a rectangle) to model its geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a72f3a",
   "metadata": {},
   "source": [
    "Since the mitsuba documentation is insufficient, here is a description of the signature of the relevant function `eval(self, si:mi.SurfaceInteraction3f, active=True)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5aaea2",
   "metadata": {},
   "source": [
    "`si:mi.SurfaceInteraction3f`: Describes the interaction (i.e., the intersection) between a traced ray of sight and the light source (for more infos see below).<br>\n",
    "`active=True`: Not needed here, can remain `True`.<br><br>\n",
    "Returns `mi.Color3f`: The spectrum emitted in the direction of the traced ray (can also be `(0.0, 0.0, 0.0)` if no light is emitted in the respective direction.).<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4240a252",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "The `si : SurfaceInteraction3f` record contains two particularly useful parameters:<br>\n",
    "`si.n : mi.Vector3f` : The normal vector of the attached shape at the evaluated intersection.<br>\n",
    "`si.wi : mi.Vector3f`: The direction of the traced ray (usually pointing towards the shape)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51e2e1",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0573ed5",
   "metadata": {},
   "source": [
    "The telecentric illumination is described via the parameters<br>\n",
    "`acc_angle`: The maximum accepted angle, i.e., the angle between a ray of sight of a sensor and the surface normal of the light source inside which light is emitted.<br>\n",
    "`radiance`: The spectrum that is emitted inside the accepted angle.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a60ce",
   "metadata": {},
   "source": [
    "Fill in the gaps in the code below, so that the parameterized spectrum `self.radiance` is only emitted, if at an intersection the angle between the surface normal and the traced ray is smaller than the accepted angle `self.acc_angle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2868a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class telecentric_area_light (mi.Emitter):\n",
    "    def __init__(self, props):\n",
    "        mi.Emitter.__init__(self, props)\n",
    "        self.acc_angle = dr.deg2rad(props['acc_angle'])\n",
    "        self.radiance = mi.Color3f(props['radiance'])\n",
    "        self.flags = mi.EmitterFlags.Surface | mi.EmitterFlags.SpatiallyVarying\n",
    "    \n",
    "    #Helper function, might be useful.\n",
    "    def angleBetweenVectors(self, a:mi.Vector3f, b:mi.Vector3f):\n",
    "        return dr.acos(dr.dot(a,b) / (dr.norm(a) * dr.norm(b)))\n",
    "    \n",
    "    def eval(self, si:mi.SurfaceInteraction3f, active=True):\n",
    "        \n",
    "        #INSERT CODE HERE\n",
    "        \n",
    "        return res\n",
    "\n",
    "    #Legacy code - needed to run without errors - but not semantically needed for this exercise.\n",
    "    def sample_direction(self, it:mi.Interaction3f, sample, active=True):\n",
    "        dirsam = mi.DirectionSample3f()\n",
    "        return (mi.DirectionSample3f(), mi.Color3f())\n",
    "    \n",
    "    def to_string(self):\n",
    "        return ('telecentric_area_light[\\n'\n",
    "                '    acc_angle=%s,\\n'\n",
    "                '    radiance=%s,\\n'\n",
    "                ']' % (dr.rad2deg(self.acc_angle), self.radiance))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa660d",
   "metadata": {},
   "source": [
    "We now register the new plugin as an emitter plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daca22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.register_emitter(\"telecentric_area_light\", lambda props: telecentric_area_light(props))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a25b1",
   "metadata": {},
   "source": [
    "Render a test scene where a telecentric camera observes a rectangular telecentric area light source. Experiment with the acceptance angle and the stop radius of the telecentric camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = mi.load_dict({\n",
    "    'type': 'scene',\n",
    "    'integrator': {\n",
    "        'type': 'path'\n",
    "    },\n",
    "\n",
    "    'rect' : {\n",
    "        'type': 'rectangle',\n",
    "        'emitter': {\n",
    "            'type': 'telecentric_area_light',\n",
    "            'radiance': mi.Color3f(1.0,1.0,1.0),\n",
    "            'acc_angle': 1.0\n",
    "    },\n",
    "        'flip_normals' : True,\n",
    "        'to_world': mi.Transform4f.translate(mi.Point3f(0,0,g))@mi.Transform4f.scale(mi.Point3f(2,2,2))\n",
    "        \n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    'sensor': {\n",
    "        'type': 'telecentric_sensor',\n",
    "        'to_world': mi.ScalarTransform4f.look_at(origin=[0, 0, 0],\n",
    "                                                 target=[0, 0, 1],\n",
    "                                                 up=[0, 1, 0]),\n",
    "        'foc_len' : f,\n",
    "        'img_dist': b,\n",
    "        'sen_size': 10.0,\n",
    "        'lens_rad': 10.0,\n",
    "        'stop_rad': 0.1000,\n",
    "        'film': {'type': 'hdrfilm',\n",
    "      'width': 100,\n",
    "      'height': 100,\n",
    "      'rfilter': {'type': 'gaussian'},\n",
    "      'pixel_format': 'rgb',\n",
    "      'component_format': 'float32'},\n",
    "     'sampler': {'type': 'independent', 'sample_count': 8},\n",
    "    }\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778e618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = mi.render(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07070a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbde29",
   "metadata": {},
   "source": [
    "## Fourier transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe04c18",
   "metadata": {},
   "source": [
    "### Convolution in the Fourier domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3002085",
   "metadata": {},
   "source": [
    "Implement a function `fourier_conv(img:np.ndarray, kernel:np.ndarray) -> np.ndarray` that performs a 2D-convolution of the input image `img` with the convolution kernel `kernel` in the Fourier domain.\n",
    "\n",
    "Validate via the function `np.allclose` and an example image that your result is equal to the result when performing the convolution in the spatial domain with `scipy.ndimage.convolve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815dd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_conv(img:np.ndarray, kernel:np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    result = np.zeros_like(img) ## replace with your solution\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5068d",
   "metadata": {},
   "source": [
    "Test your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09410bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.float32(misc.face(gray=True))[0:-1, 0:-1]\n",
    "kernel = np.ones((51,51))\n",
    "\n",
    "res_fourier = fourier_conv(img, kernel)\n",
    "res_spatial = ndimage.convolve(img, kernel, mode='???') ## Which mode do you have to use?\n",
    "\n",
    "print(f\"Is your solution correct: {np.allclose(res_fourier, res_spatial)}\")\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(res_spatial, cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(res_fourier, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece95d4b",
   "metadata": {},
   "source": [
    "### Hybrid images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba5995",
   "metadata": {},
   "source": [
    "Read the paper\n",
    "\n",
    "*Hybrid images* by Aude Oliva et al. (https://dl.acm.org/doi/abs/10.1145/1141911.1141919).\n",
    "\n",
    "Implement a function that takes two input images and combines them by high pass-filtering the first one and low pass-filtering the second one, so that in the resulting images, the first original image can be seen when viewing from a close distance and the second original image can be seen from a far distance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compimg",
   "language": "python",
   "name": "compimg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
