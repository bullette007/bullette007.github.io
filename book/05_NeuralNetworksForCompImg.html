
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Neural Networks for Computational Imaging &#8212; Computational Imaging - Course Notes</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inverse Problems in Computational Imaging" href="06_InverseProblemsInCompimg.html" />
    <link rel="prev" title="Light Transport Analysis" href="04_LightTransportAnalysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Computational Imaging - Course Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Computational Imaging - Course Notes for Winter Term 2023 / 2024
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_Introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_Basics.html">
   Fundamental Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_LightFieldMethods.html">
   Light Field Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_LightTransportAnalysis.html">
   Light Transport Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Neural Networks for Computational Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_InverseProblemsInCompimg.html">
   Inverse Problems in Computational Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_LenslessImaging.html">
   Lensless Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_CodedExposurePhotography.html">
   Coded Exposure Photography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_QuantitativePhaseImaging.html">
   Quantitative Phase Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_SpectralSnapshotImaging.html">
   Coded Aperture Spectral Snapshot Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_TimeOfFlightImaging.html">
   Time-Of-Flight Imaging
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/05_NeuralNetworksForCompImg.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="_sources/05_NeuralNetworksForCompImg.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#content">
   Content
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-to-neural-networks">
   Introduction to neural networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#principal-building-blocks">
   Principal building blocks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#layers">
     Layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-layers">
     Linear layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#non-linear-layers">
     Non-linear layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-popular-non-linear-functions">
       Other popular non-linear functions
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sigmoid">
         Sigmoid
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#rectified-linear-unit-relu">
         Rectified linear unit (ReLU)
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#softplus">
         Softplus
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#leaky-relu">
         Leaky ReLU
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#exponential-linear-unit-elu">
         Exponential linear unit (ELU)
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#hyperbolic-tangent-tanh">
         Hyperbolic tangent (tanh)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pooling-layers">
     Pooling layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-max-pooling-with-pytorch">
       Example max pooling with PyTorch:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-layers">
     Convolutional layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#channel-dimensions">
       Channel dimensions
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#times-1-convolutions">
       <span class="math notranslate nohighlight">
        \(1 \times 1\)
       </span>
       convolutions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transposed-convolutional-layers">
     Transposed convolutional layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-transposed-convolution-with-pytorch">
       Example transposed convolution with PyTorch:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#upsampling-layer">
     Upsampling layer
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-upsampling-with-pytorch">
       Example upsampling with PyTorch:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization-layers">
     Batch normalization layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#softmax-layers">
     Softmax layers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#universal-approximation-theorem">
   Universal approximation theorem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimization-of-network-parameters">
   Optimization of network parameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-descent">
     Gradient descent
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-chain-rule-and-the-backpropagation-algorithm">
     The chain rule and the backpropagation algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-implementation-for-y-log-x-2">
       Example implementation for
       <span class="math notranslate nohighlight">
        \(y = \log (x)^2\)
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automatic-differentiation">
     Automatic differentiation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#architectures-and-loss-functions">
   Architectures and loss functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-convolutional-networks-for-image-classification">
     Deep convolutional networks for image classification
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-entropy-loss">
       Cross-entropy loss
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#residual-nets-skip-connections">
     Residual nets / skip connections
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encoder-decoder-modules">
     Encoder / decoder modules
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mean-squared-error-loss">
       Mean squared error loss
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#anomaly-detection-for-visual-inspection">
       Anomaly detection for visual inspection
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#variational-auto-encoders">
       Variational auto encoders
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#u-net-for-segmentation-or-regression-tasks">
     U-Net for segmentation or regression tasks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-applications">
   Example applications
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#denoising-with-neural-networks">
     Denoising with neural networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learned-image-signal-processing-unit">
     Learned image signal processing unit
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learned-optics-for-single-shot-high-dynamic-range-imaging">
     Learned optics for single-shot high-dynamic-range imaging
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tools-libraries-and-reading-resources">
   Tools, libraries and reading resources
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Neural Networks for Computational Imaging</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#content">
   Content
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-to-neural-networks">
   Introduction to neural networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#principal-building-blocks">
   Principal building blocks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#layers">
     Layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-layers">
     Linear layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#non-linear-layers">
     Non-linear layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-popular-non-linear-functions">
       Other popular non-linear functions
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sigmoid">
         Sigmoid
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#rectified-linear-unit-relu">
         Rectified linear unit (ReLU)
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#softplus">
         Softplus
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#leaky-relu">
         Leaky ReLU
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#exponential-linear-unit-elu">
         Exponential linear unit (ELU)
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#hyperbolic-tangent-tanh">
         Hyperbolic tangent (tanh)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pooling-layers">
     Pooling layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-max-pooling-with-pytorch">
       Example max pooling with PyTorch:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-layers">
     Convolutional layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#channel-dimensions">
       Channel dimensions
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#times-1-convolutions">
       <span class="math notranslate nohighlight">
        \(1 \times 1\)
       </span>
       convolutions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transposed-convolutional-layers">
     Transposed convolutional layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-transposed-convolution-with-pytorch">
       Example transposed convolution with PyTorch:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#upsampling-layer">
     Upsampling layer
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-upsampling-with-pytorch">
       Example upsampling with PyTorch:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization-layers">
     Batch normalization layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#softmax-layers">
     Softmax layers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#universal-approximation-theorem">
   Universal approximation theorem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimization-of-network-parameters">
   Optimization of network parameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-descent">
     Gradient descent
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-chain-rule-and-the-backpropagation-algorithm">
     The chain rule and the backpropagation algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-implementation-for-y-log-x-2">
       Example implementation for
       <span class="math notranslate nohighlight">
        \(y = \log (x)^2\)
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automatic-differentiation">
     Automatic differentiation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#architectures-and-loss-functions">
   Architectures and loss functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-convolutional-networks-for-image-classification">
     Deep convolutional networks for image classification
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-entropy-loss">
       Cross-entropy loss
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#residual-nets-skip-connections">
     Residual nets / skip connections
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encoder-decoder-modules">
     Encoder / decoder modules
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mean-squared-error-loss">
       Mean squared error loss
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#anomaly-detection-for-visual-inspection">
       Anomaly detection for visual inspection
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#variational-auto-encoders">
       Variational auto encoders
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#u-net-for-segmentation-or-regression-tasks">
     U-Net for segmentation or regression tasks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-applications">
   Example applications
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#denoising-with-neural-networks">
     Denoising with neural networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learned-image-signal-processing-unit">
     Learned image signal processing unit
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learned-optics-for-single-shot-high-dynamic-range-imaging">
     Learned optics for single-shot high-dynamic-range imaging
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tools-libraries-and-reading-resources">
   Tools, libraries and reading resources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell tag_remove-input tag_book_only docutils container">
</div>
<p><span class="math notranslate nohighlight">\(\begin{align}
  \newcommand{transp}{^\intercal}
  \newcommand{F}{\mathcal{F}}
  \newcommand{Fi}{\mathcal{F}^{-1}}
  \newcommand{inv}{^{-1}}
  \newcommand{stochvec}[1]{\mathbf{\tilde{#1}}}
  \newcommand{argmax}[1]{\underset{#1}{\mathrm{arg\, max}}}
  \newcommand{argmin}[1]{\underset{#1}{\mathrm{arg\, min}}}
\end{align}\)</span></p>
<p><font size="7"> Computational Imaging </font><br><br><br></p>
<section class="tex2jax_ignore mathjax_ignore" id="neural-networks-for-computational-imaging">
<h1>Neural Networks for Computational Imaging<a class="headerlink" href="#neural-networks-for-computational-imaging" title="Permalink to this headline">#</a></h1>
<section id="content">
<h2>Content<a class="headerlink" href="#content" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Introduction to neural networks</p></li>
<li><p>Principal building blocks</p></li>
<li><p>Universal approximation theorem</p></li>
<li><p>Optimization of network parameters</p></li>
<li><p>Architectures and loss functions</p></li>
<li><p>Example applications</p></li>
<li><p>Tools, libraries and reading resources</p></li>
</ul>
</section>
<section id="introduction-to-neural-networks">
<h2>Introduction to neural networks<a class="headerlink" href="#introduction-to-neural-networks" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>(Artificial) neural networks represent a class of machine learning methods.</p></li>
<li><p>They can be imagined as versatile approximators <span class="math notranslate nohighlight">\(\phi_\boldsymbol{\theta}\)</span> of arbitrary, continuous functions <span class="math notranslate nohighlight">\(\mathbf{y} = f(\mathbf{x}), \quad f:\mathbb{R}^N \mapsto \mathbb{R}^M,\quad M,N \in \mathbb{N}\)</span>, i.e., with <span class="math notranslate nohighlight">\(\phi_\boldsymbol{\theta}(\mathbf{x}) \approx f(\mathbf{x})\)</span>.</p></li>
<li><p>They are defined by their architecture and the corresponding parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>Via a suitable training procedure and a so-called <em>training set</em> of example pairs <span class="math notranslate nohighlight">\(\mathcal{T} = \left\{ (\mathbf{x}_i, \mathbf{y}_i), i \in \left[ 1,\ldots , N \right]  \right\}\)</span> of input variables <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> and corresponding output variables <span class="math notranslate nohighlight">\(\mathbf{y}_i\)</span>, their parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> are optimized so that</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\forall (\mathbf{x},\mathbf{y}) \in \mathcal{T}:\text{dist}(\phi_\boldsymbol{\theta}(\mathbf{x}), \mathbf{y} ) \rightarrow \text{Min.}\,,\)</span> with a suitable distance function <span class="math notranslate nohighlight">\(\text{dist}\)</span> and</p></li>
<li><p>(hopefully) <span class="math notranslate nohighlight">\(\text{dist}(\phi_\boldsymbol{\theta}(\mathbf{x}), f(\mathbf{x}) ) \rightarrow \text{Min.}\,,\)</span> for unseen input vectors <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, i.e., which are not part of the training set.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Neural networks have first been described in 1943 by Warren McCulloch and Walter Pitts in their paper “A Logical Calculus of the Ideas Immanent in Nervous Activity”.</p></li>
<li><p>Frank Rosenblatt followed their approach and described the so-called <em>Perceptron</em> as a fundamental unit of early neural networks.</p></li>
</ul>
<ul class="simple">
<li><p>Approximately around the year 2010, researchers started to use very deep neural networks, i.e., with many so-called <em>layers</em> (more information later) and achieved unprecedented performances on various tasks in the field of machine learning and computer vision.</p></li>
</ul>
<ul class="simple">
<li><p>An important enabler for this breakthrough were the increase in computing power provided by modern computers, especially by GPUs (graphics processing units), and the availability and usage of huge amounts of training data.</p></li>
</ul>
</section>
<section id="principal-building-blocks">
<h2>Principal building blocks<a class="headerlink" href="#principal-building-blocks" title="Permalink to this headline">#</a></h2>
<p>The two fundamental building blocks of neural networks are</p>
<ul class="simple">
<li><p>Matrix vector multiplications and</p></li>
<li><p>non-linear functions, also called or <em>activation functions</em>.</p></li>
</ul>
<p>Multiple instances of these building blocks can be stacked in parallel or consecutively with respect to each other to finally yield a neural network.</p>
<section id="layers">
<h3>Layers<a class="headerlink" href="#layers" title="Permalink to this headline">#</a></h3>
<p>When stacking linear or non-linear building blocks in parallel, the resulting structure is called a linear, respectively, a non-linear layer (usually either a linear or a non-linear block is stacked in parallel, not a mixture of both).</p>
<p>The way of stacking the individual blocks is called the <em>architecture</em> of the neural network.</p>
</section>
<section id="linear-layers">
<h3>Linear layers<a class="headerlink" href="#linear-layers" title="Permalink to this headline">#</a></h3>
<p>In one building block of a linear layer, the input <span class="math notranslate nohighlight">\((x_1, x_2, \ldots, x_N)\transp\)</span> is mapped to the scalar output <span class="math notranslate nohighlight">\(y\)</span> via a linear transformation, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   y = \sum\limits^{N}_{i=1} w_i \cdot x_i + b \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(w_i\)</span> denoting the <span class="math notranslate nohighlight">\(i\)</span>-th so-called <em>weight</em>, i.e. parameter, of this block and <span class="math notranslate nohighlight">\(b\)</span> denoting the so-called <em>bias</em> (also a parameter), i.e., an additive term not depending on the input.</p>
<img src="figures/5/single_block_linear_only.svg" style="max-height:40vh"><p>When one input is simultaneously processed by <span class="math notranslate nohighlight">\(K\)</span> linear blocks, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   y_k = \sum\limits^{N}_{i=1} w^k_i \cdot x_i + b^k = \underbrace{\left( w^k_1, w^k_2, \ldots, w^k_N, b^k \right)}_{\mathbf{w}\transp_k} \cdot \underbrace{\begin{pmatrix} 
      x_1 \\ x_2 \\ \vdots \\ x_N \\ 1
   \end{pmatrix}}_{\mathbf{x}}  \,,
\end{align}\)</span></p>
<p>for block <span class="math notranslate nohighlight">\(k\)</span>, this can be expressed compactly via matrix-vector multiplications:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \begin{pmatrix} 
      y_1 \\ y_2 \\ \vdots \\ y_K
   \end{pmatrix}
   &amp;= 
   \begin{pmatrix} 
      \qquad \mathbf{w}\transp_1 \qquad  \\ \mathbf{w}\transp_2 \\ \vdots \\ \mathbf{w}\transp_K
   \end{pmatrix} \cdot 
   \begin{pmatrix} 
      x_1 \\ x_2 \\ \vdots \\ x_N \\ 1
   \end{pmatrix} \\
   &amp;= \qquad \quad \mathbf{W} \quad \qquad \cdot \quad  \mathbf{x} \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\mathbf{W} \in \mathbb{R}^{K \times (N+1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{(N+1) \times 1}\)</span>.</p>
<img src="figures/5/single_layer_linear_only.svg" style="max-height:40vh"><p>This expression can be further extended for the case when multiple input vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_B\)</span>, i.e., a so-called <em>batch</em> of size <span class="math notranslate nohighlight">\(B\)</span>, have to be processed simultaneously:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \begin{pmatrix} 
    \qquad \mathbf{w}\transp_1 \qquad  \\ \mathbf{w}\transp_2 \\ \vdots \\ \mathbf{w}\transp_K
 \end{pmatrix} \cdot 
 \begin{pmatrix} 
     \\  \\ \mathbf{x}_1 &amp; \mathbf{x}_2 &amp; \cdots &amp; \mathbf{x}_B    \\ \\ \\
 \end{pmatrix} &amp;= \begin{pmatrix} 
    \mathbf{w}\transp_1 \cdot \mathbf{x}_1 &amp; \mathbf{w}\transp_1 \cdot \mathbf{x}_2 &amp;\cdots &amp;\mathbf{w}\transp_1 \cdot \mathbf{x}_B \\ 
    \mathbf{w}\transp_2 \cdot \mathbf{x}_1 &amp; \mathbf{w}\transp_2 \cdot \mathbf{x}_2 &amp;\cdots &amp;\mathbf{w}\transp_2 \cdot \mathbf{x}_B \\     
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    \mathbf{w}\transp_K \cdot \mathbf{x}_1 &amp; \mathbf{w}\transp_K \cdot \mathbf{x}_2 &amp;\cdots &amp;\mathbf{w}\transp_K \cdot \mathbf{x}_B \\ 
 \end{pmatrix}\\
 &amp;= \begin{pmatrix} 
  \\  \\ \mathbf{y}_1 &amp; \mathbf{y}_2 &amp; \cdots &amp; \mathbf{y}_B    \\ \\ \\
\end{pmatrix}
 \,.
\end{align}\)</span></p>
<p>Although not fully correct, linear layers are sometimes also referred to as <em>feed forward layers</em> or <em>multi-layer perceptron (MLP)</em>.</p>
</section>
<section id="non-linear-layers">
<h3>Non-linear layers<a class="headerlink" href="#non-linear-layers" title="Permalink to this headline">#</a></h3>
<p>Neural networks constructed only out of linear layers are very limited in their approximation abilities since in essence they just represent a long linear function and hence can only mimic linear functions.</p>
<p>This is why additional, so-called <em>non-linear layers</em> consisting of non-linear building blocks are necessary.</p>
<p>In general, a non-linear building block is a non-linear function <span class="math notranslate nohighlight">\(\psi:\mathbb{R}\rightarrow \mathbb{R}\)</span> that is applied to the scalar output of a linear building block.</p>
<p>The combination of a linear and a non-linear block then looks like:</p>
<img src="figures/5/single_block.svg" style="max-height:40vh"><p>And a corresponding layer looks like:</p>
<img src="figures/5/single_layer.svg" style="max-height:40vh"><p>A popular example for a non-linearity is the so-called <em>sigmoid</em>-function</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \psi(y)=\frac{1}{1+\mathrm{e}^{-y} } \,.
\end{align}\)</span></p>
<p>When choosing high values for <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> in the preceding linear block, the sigmoid-function resembles a unit step-function which can be shifted left or right by adjusting the bias <span class="math notranslate nohighlight">\(b\)</span>:</p>
<div class="cell tag_delete-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">x</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">plot_sigmoid_after_linear</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">y1s</span> <span class="o">=</span> <span class="n">xs</span><span class="o">*</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">y2s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">y1s</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span><span class="n">y2s</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">:</span> <span class="n">plot_sigmoid_after_linear</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">),</span> <span class="n">w</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">b</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "ca8680b4d62043f9944ad51d902f445a"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(w, b)&gt;
</pre></div>
</div>
</div>
</div>
<p>In batch processing, the result of a batch of data processed by a linear layer, i.e. <span class="math notranslate nohighlight">\(\mathbf{y} = \mathbf{Wx}\)</span>, is processed by the non-linearity in an element-wise fashion.</p>
<section id="other-popular-non-linear-functions">
<h4>Other popular non-linear functions<a class="headerlink" href="#other-popular-non-linear-functions" title="Permalink to this headline">#</a></h4>
<div class="cell tag_delete-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ys_softplus</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">ys_leakyrelu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">ys_elu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">ys_relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">ys_tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">ys_sigm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span><span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="sigmoid">
<h5>Sigmoid<a class="headerlink" href="#sigmoid" title="Permalink to this headline">#</a></h5>
<p>The <em>sigmoid function</em>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \sigma(x) = \frac{1}{1+\exp(-x)} \,.
\end{align}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_sigm</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.01</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;sigmoid.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05_NeuralNetworksForCompImg_36_0.png" src="_images/05_NeuralNetworksForCompImg_36_0.png" />
</div>
</div>
</section>
<section id="rectified-linear-unit-relu">
<h5>Rectified linear unit (ReLU)<a class="headerlink" href="#rectified-linear-unit-relu" title="Permalink to this headline">#</a></h5>
<p>The <em>rectified linear unit (ReLU)</em> with <span class="math notranslate nohighlight">\(\mathrm{ReLU}(x) = \max (0,x)\)</span> is a good general purpose activation function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_relu</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.01</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ReLU (rectified linear unit)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.75</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span>  <span class="mf">0.</span>  <span class="p">,</span>  <span class="mf">0.25</span><span class="p">,</span>  <span class="mf">0.5</span> <span class="p">,</span>  <span class="mf">0.75</span><span class="p">,</span>  <span class="mf">1.</span>  <span class="p">,</span> <span class="mf">1.25</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.6</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span>  <span class="mf">0.</span>  <span class="p">,</span>  <span class="mf">0.2</span><span class="p">,</span>  <span class="mf">0.4</span> <span class="p">,</span>  <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span>  <span class="mf">1.</span> <span class="p">]</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;relu.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05_NeuralNetworksForCompImg_40_0.png" src="_images/05_NeuralNetworksForCompImg_40_0.png" />
</div>
</div>
</section>
<section id="softplus">
<h5>Softplus<a class="headerlink" href="#softplus" title="Permalink to this headline">#</a></h5>
<p>Smooth approximation of the ReLU function:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   y_i = \frac{1}{\beta} \cdot \log \left( 1 + \exp (\beta \cdot x_i) \right) \,,
\end{align}\)</span></p>
<p>with parameter <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_softplus</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Softplus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05_NeuralNetworksForCompImg_42_0.png" src="_images/05_NeuralNetworksForCompImg_42_0.png" />
</div>
</div>
</section>
<section id="leaky-relu">
<h5>Leaky ReLU<a class="headerlink" href="#leaky-relu" title="Permalink to this headline">#</a></h5>
<p>Similar to ReLU but with a non-zero slope for negative inputs:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{LeakyReLU}(x) = \begin{cases} 
      x, &amp; \text{if } x \geq 0 \\
      \beta \cdot x, &amp; \text{otherwise}
   \end{cases} \,,
\end{align}\)</span></p>
<p>with the negative slope value <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_leakyrelu</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;leaky ReLU (rectified linear unit)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05_NeuralNetworksForCompImg_44_0.png" src="_images/05_NeuralNetworksForCompImg_44_0.png" />
</div>
</div>
</section>
<section id="exponential-linear-unit-elu">
<h5>Exponential linear unit (ELU)<a class="headerlink" href="#exponential-linear-unit-elu" title="Permalink to this headline">#</a></h5>
<p>Another smooth approximation of the ReLU function:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{ELU}(x) = \begin{cases} 
      x, &amp; \text{if } x &gt; 0 \\
      \exp (x) -1 &amp; \text{otherwise} 
   \end{cases}\,.
\end{align}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_elu</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ELU (exponential linear unit)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05_NeuralNetworksForCompImg_46_0.png" src="_images/05_NeuralNetworksForCompImg_46_0.png" />
</div>
</div>
</section>
<section id="hyperbolic-tangent-tanh">
<h5>Hyperbolic tangent (tanh)<a class="headerlink" href="#hyperbolic-tangent-tanh" title="Permalink to this headline">#</a></h5>
<p>The <em>hyperbolic tangent (tanh)</em> function:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{tanh}(x) = \frac{\exp (x) - \exp (-x)}{\exp (x) + \exp (-x)} \,.
\end{align}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_tanh</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05_NeuralNetworksForCompImg_48_0.png" src="_images/05_NeuralNetworksForCompImg_48_0.png" />
</div>
</div>
</section>
</section>
</section>
<section id="pooling-layers">
<h3>Pooling layers<a class="headerlink" href="#pooling-layers" title="Permalink to this headline">#</a></h3>
<p>Pooling layers reduce the size of the input data by selecting or calculating a certain value out of a region of input values and by replacing that whole region by this value.</p>
<p>A common example is <em>max pooling</em>. The layer is parameterized via</p>
<ul class="simple">
<li><p>its window size <span class="math notranslate nohighlight">\(h\)</span> and</p></li>
<li><p>its stride <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
</ul>
<p>The layer shifts a square-shaped window with edge length <span class="math notranslate nohighlight">\(h\)</span> over the input data and selects the highest value out of all values covered by the window and returns this value as one of its outputs. Then, the window is shifted by the stride value <span class="math notranslate nohighlight">\(s\)</span> and the procedure is repeated until the whole input data has been processed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">showFig</span><span class="p">(</span><span class="s1">&#39;figures/5/pooling_layer_&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;.svg&#39;</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">i</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="p">(</span><span class="n">min_i</span><span class="o">:=</span><span class="mi">1</span><span class="p">),</span><span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span><span class="o">:=</span><span class="mi">5</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span> <span class="k">if</span> <span class="n">book</span> <span class="k">else</span> <span class="n">min_i</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "8fa28092c3f74aaa8e8602bce9430263"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(i)&gt;
</pre></div>
</div>
</div>
</div>
<section id="example-max-pooling-with-pytorch">
<h4>Example max pooling with PyTorch:<a class="headerlink" href="#example-max-pooling-with-pytorch" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pooling</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">tens</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[2., 1., 1., 1.],
         [1., 2., 1., 1.],
         [1., 1., 2., 1.],
         [1., 1., 1., 2.]]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pooling</span><span class="p">(</span><span class="n">tens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[2., 1.],
         [1., 2.]]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="convolutional-layers">
<h3>Convolutional layers<a class="headerlink" href="#convolutional-layers" title="Permalink to this headline">#</a></h3>
<p>Convolutional layers process their input by convolving it with one or more convolution kernels.</p>
<p>The coefficients of the convolution kernels also represent parameters of the network which are optimized during training.</p>
<p>Convolutional layers are mainly parameterized via</p>
<ul class="simple">
<li><p>number of kernels (often referred to as <em>channels</em>),</p></li>
<li><p>sizes of the kernels,</p></li>
<li><p>their stride <span class="math notranslate nohighlight">\(s\)</span> and</p></li>
<li><p>the padding mode (i.e., how to deal with the situation at the borders of the input data when the kernel protrudes the input’s support).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">showFig</span><span class="p">(</span><span class="s1">&#39;figures/5/convolutional_layer_&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;.svg&#39;</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">i</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="p">(</span><span class="n">min_i</span><span class="o">:=</span><span class="mi">0</span><span class="p">),</span><span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span><span class="o">:=</span><span class="mi">5</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span> <span class="k">if</span> <span class="n">book</span> <span class="k">else</span> <span class="n">min_i</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "90b7ad9ea50c415cbe7ae92b5b8be6d6"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(i)&gt;
</pre></div>
</div>
</div>
</div>
<p>Depending on the stride <span class="math notranslate nohighlight">\(s\)</span> and the padding mode, convolutional layers can yield outputs of lower spatial dimensions (e.g., smaller images).</p>
<p>Depending on the number of kernels, the output can have a larger or lower number of channels.</p>
<section id="channel-dimensions">
<h4>Channel dimensions<a class="headerlink" href="#channel-dimensions" title="Permalink to this headline">#</a></h4>
<p>If the input to a convolutional layer has <span class="math notranslate nohighlight">\(C\)</span> channels, each filter kernel must also have <span class="math notranslate nohighlight">\(C\)</span> channels. Considering one kernel, the individual channels of the input are convolved with the respective channels of that kernel and the results are summed up to yield one channel of the output of the layer. Hence, every kernel yields one channel of the output.</p>
</section>
<section id="times-1-convolutions">
<h4><span class="math notranslate nohighlight">\(1 \times 1\)</span> convolutions<a class="headerlink" href="#times-1-convolutions" title="Permalink to this headline">#</a></h4>
<p>In order to reduce the channel dimension while processing data in a neural network, so-called <span class="math notranslate nohighlight">\(1 \times 1\)</span> <em>convolutions</em>, i.e., convolutions with a kernel of size <span class="math notranslate nohighlight">\(1 \times 1\)</span> can be employed.</p>
<p>A <span class="math notranslate nohighlight">\(1 \times 1\)</span>-kernel does not alter the spatial distribution of the data but can reduce the channel dimension if the number of <span class="math notranslate nohighlight">\(1 \times 1\)</span>-kernels is less than the number of channels of the input data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sometimes, the results of a convolutional layer are denoted as <em>features</em> or <em>feature maps</em>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In many programming libraries for neural networks, biases (i.e., additive terms) are also added to the results of convolutional layers. This can lead to unexpected results if it is not considered.</p>
</div>
</section>
</section>
<section id="transposed-convolutional-layers">
<h3>Transposed convolutional layers<a class="headerlink" href="#transposed-convolutional-layers" title="Permalink to this headline">#</a></h3>
<p>Although the name might be a bit misleading, so-called <em>transposed convolutional layers</em> can be imagined as a kind of inverse of convolutional layers, in the sense as they increase the spatial resolution of the input.</p>
<p>Transposed convolutional layers are parameterized similarly to convolutional layers, i.e., via</p>
<ul class="simple">
<li><p>number of kernels,</p></li>
<li><p>sizes of the kernels,</p></li>
<li><p>their stride <span class="math notranslate nohighlight">\(s\)</span> and</p></li>
<li><p>the padding mode.</p></li>
</ul>
<p>Every element of the input scales a kernel which yields the values of the output in the spatial region covered by the kernel. The kernel is then shifted by the stride <span class="math notranslate nohighlight">\(s\)</span> and the process is repeated with the next value of the input vector. Depending on the stride <span class="math notranslate nohighlight">\(s\)</span>, there might already be values present in the currently considered region of the output vector. In that case, the new values are additively superposed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">showFig</span><span class="p">(</span><span class="s1">&#39;figures/5/transposed_convolutional_layer_&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;.svg&#39;</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">i</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="p">(</span><span class="n">min_i</span><span class="o">:=</span><span class="mi">0</span><span class="p">),</span><span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span><span class="o">:=</span><span class="mi">3</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span> <span class="k">if</span> <span class="n">book</span> <span class="k">else</span> <span class="n">min_i</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "a559380a9502488085fcfa2862711755"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(i)&gt;
</pre></div>
</div>
</div>
</div>
<section id="example-transposed-convolution-with-pytorch">
<h4>Example transposed convolution with PyTorch:<a class="headerlink" href="#example-transposed-convolution-with-pytorch" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transposed_convolution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">transposed_convolution</span><span class="o">.</span><span class="n">weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([[[[ 0.2889, -0.3182, -0.2989],
          [ 0.2601, -0.2499, -0.2578],
          [ 0.1413,  0.3271,  0.3184]]]], requires_grad=True)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">only_one_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]]))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">only_one_tensor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[1., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transposed_convolution</span><span class="p">(</span><span class="n">only_one_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 0.2889, -0.3182, -0.2989,  0.0000,  0.0000],
         [ 0.2601, -0.2499, -0.2578,  0.0000,  0.0000],
         [ 0.1413,  0.3271,  0.3184,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],
       grad_fn=&lt;SqueezeBackward1&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eye_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">eye_tensor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[1., 0., 0.],
         [0., 1., 0.],
         [0., 0., 1.]]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transposed_convolution</span><span class="p">(</span><span class="n">eye_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 0.2889, -0.3182, -0.2989,  0.0000,  0.0000],
         [ 0.2601,  0.0390, -0.5760, -0.2989,  0.0000],
         [ 0.1413,  0.5873,  0.3574, -0.5760, -0.2989],
         [ 0.0000,  0.1413,  0.5873,  0.0685, -0.2578],
         [ 0.0000,  0.0000,  0.1413,  0.3271,  0.3184]]],
       grad_fn=&lt;SqueezeBackward1&gt;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="upsampling-layer">
<h3>Upsampling layer<a class="headerlink" href="#upsampling-layer" title="Permalink to this headline">#</a></h3>
<p>Another possibility to increase the spatial resolution of the data is to employ so-called <em>upsampling layers</em>. The missing values in the resulting higher-dimensional output are usually calculated via any common interpolation method (e.g., bilinear, nearest neighbor, etc.).</p>
<img src="figures/5/upsampling_layer.svg" style="max-height:40vh"><section id="example-upsampling-with-pytorch">
<h4>Example upsampling with PyTorch:<a class="headerlink" href="#example-upsampling-with-pytorch" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">upsample_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">upsample_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[[1., 1., 0., 0., 0., 0.],
          [1., 1., 0., 0., 0., 0.],
          [0., 0., 1., 1., 0., 0.],
          [0., 0., 1., 1., 0., 0.],
          [0., 0., 0., 0., 1., 1.],
          [0., 0., 0., 0., 1., 1.]]]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="batch-normalization-layers">
<h3>Batch normalization layers<a class="headerlink" href="#batch-normalization-layers" title="Permalink to this headline">#</a></h3>
<p>It has been shown to be beneficial for the training procedure if the outputs of neural network layers are normalized w.r.t. the mean and variance of the currently processed batch of training data. For this purpose, so-called <em>batch normalization layers</em> can be employed.</p>
<p>During every training iteration, they normalize their input vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> via:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   y_i = \frac{x_i - \mu_i}{\sqrt{\sigma^2_i+ \epsilon}} \cdot \gamma + \beta \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\mu_i , \sigma^2_i\)</span> denoting the mean, respectively, the variance of the <span class="math notranslate nohighlight">\(i\)</span>-th element of the input estimated over the processed batch of training data and <span class="math notranslate nohighlight">\(\beta, \gamma\)</span> representing the mean, respectively, the standard deviation assigned after the normalization. The parameters <span class="math notranslate nohighlight">\(\beta, \gamma\)</span> can also be learned during training and are typically initialized with <span class="math notranslate nohighlight">\(\beta = 0, \gamma = 1\)</span>.</p>
<p>Typical implementations of batch normalization layers aggregate the estimated statistics over all training iterations in order to use them when the neural network is evaluated in forward mode.</p>
</section>
<section id="softmax-layers">
<h3>Softmax layers<a class="headerlink" href="#softmax-layers" title="Permalink to this headline">#</a></h3>
<p>Softmax layers apply the the so-called <em>softmax</em> function to their input. The input values are rescaled, so that they sum up to one and can be interpreted as a probability distribution.</p>
<p>The softmax function is defined as:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{Softmax}(x_i) = \frac{\exp (x_i)}{\sum\limits_j \exp (x_j) } \,.
\end{align}\)</span></p>
</section>
</section>
<section id="universal-approximation-theorem">
<h2>Universal approximation theorem<a class="headerlink" href="#universal-approximation-theorem" title="Permalink to this headline">#</a></h2>
<p>It could be shown, that a neural network consisting only of one (sufficiently large) linear layer and one non-linear layer (together called one <em>hidden layer</em>) which are combined by a single linear building block (a so-called <em>fully connected layer</em>) can approximate any continuous function.</p>
<p>In the following, we will sketch the proof of that theorem.</p>
<img src="figures/5/one_hidden_layer.svg" style="max-height:40vh"><p>Consider again the sigmoid function <span class="math notranslate nohighlight">\(\psi\)</span> from before applied to a linear block, i.e., <span class="math notranslate nohighlight">\(\psi(wx+b)\)</span>  form before.</p>
<p>The position of the unit step approximated by <span class="math notranslate nohighlight">\(\psi\)</span> for high <span class="math notranslate nohighlight">\(w\)</span> resides at the position <span class="math notranslate nohighlight">\(s=-\frac{b}{w}\)</span>. Since this is easier to interpret, we will focus on the parameter <span class="math notranslate nohighlight">\(s\)</span> from now on.</p>
<p>We now consider two of such blocks added together by an additional single linear building block, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \psi_{s_1} (x)\cdot w_1 + \psi_{s_2}(x)\cdot w_2  + b
\end{align}\)</span></p>
<p>with the respective positions <span class="math notranslate nohighlight">\(s_1, s_2\)</span> of the step functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="n">w</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">s</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">w</span> <span class="o">+</span> <span class="n">b</span>
<span class="k">def</span> <span class="nf">plot_2_neurons</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">):</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">y1s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">s1</span><span class="p">))</span>
    <span class="n">y2s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">s2</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">*</span> <span class="n">y1s</span> <span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="n">y2s</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span><span class="n">res</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">:</span> <span class="n">plot_2_neurons</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">),</span> \
         <span class="n">s1</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span> \
         <span class="n">s2</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">),</span> \
         <span class="n">w1</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.4</span><span class="p">),</span> \
         <span class="n">w2</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "358e1f7856ff4ec6a19513bc08d74f7a"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(s1, s2, w1, w2)&gt;
</pre></div>
</div>
</div>
</div>
<p>As can be seen, this addition yields to consecutive step functions what can be used, e.g., to approximate the <span class="math notranslate nohighlight">\(\mathrm{rect}\)</span>-function.</p>
<p>Therefore, if <span class="math notranslate nohighlight">\(s_1 &lt; s_2\)</span>, it must hold <span class="math notranslate nohighlight">\(w_2 = -w_1\)</span> to get a <span class="math notranslate nohighlight">\(\mathrm{rect}\)</span>-function with height <span class="math notranslate nohighlight">\(h=\left| w_1 \right| = \left| w_2 \right|  \)</span>.</p>
<p>We can now add two of such pairs of blocks together to model two <span class="math notranslate nohighlight">\(\mathrm{rect}\)</span>-functions, i.e., with start, stop positions <span class="math notranslate nohighlight">\(s_{1,1}, s_{1,2}\)</span> and height <span class="math notranslate nohighlight">\(h_1\)</span> of the first <span class="math notranslate nohighlight">\(\mathrm{rect}\)</span>-function and <span class="math notranslate nohighlight">\(s_{2,1}, s_{2,2}, h_2\)</span> for the second one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rect_approx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">h</span>
    <span class="n">w2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">h</span>
    <span class="n">y1s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s1</span><span class="p">))</span>
    <span class="n">y2s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">s2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">w1</span> <span class="o">*</span> <span class="n">y1s</span> <span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="n">y2s</span>
    
<span class="k">def</span> <span class="nf">plot_2_rects</span><span class="p">(</span><span class="n">s11</span><span class="p">,</span> <span class="n">s12</span><span class="p">,</span> <span class="n">s21</span><span class="p">,</span> <span class="n">s22</span><span class="p">,</span> <span class="n">h1</span><span class="p">,</span> <span class="n">h2</span><span class="p">):</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">y1s</span> <span class="o">=</span> <span class="n">rect_approx</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">s11</span><span class="p">,</span> <span class="n">s12</span><span class="p">,</span> <span class="n">h1</span><span class="p">)</span>
    <span class="n">y2s</span> <span class="o">=</span> <span class="n">rect_approx</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">s21</span><span class="p">,</span> <span class="n">s22</span><span class="p">,</span> <span class="n">h2</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">y1s</span> <span class="o">+</span> <span class="n">y2s</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span><span class="n">res</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s11</span><span class="p">,</span> <span class="n">s12</span><span class="p">,</span> <span class="n">s21</span><span class="p">,</span> <span class="n">s22</span><span class="p">,</span> <span class="n">h1</span><span class="p">,</span> <span class="n">h2</span><span class="p">:</span> <span class="n">plot_2_rects</span><span class="p">(</span><span class="n">s11</span><span class="p">,</span> <span class="n">s12</span><span class="p">,</span> <span class="n">s21</span><span class="p">,</span> <span class="n">s22</span><span class="p">,</span> <span class="n">h1</span><span class="p">,</span> <span class="n">h2</span><span class="p">),</span> \
         <span class="n">s11</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span> \
         <span class="n">s12</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span> \
         <span class="n">s21</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.4</span><span class="p">),</span> \
         <span class="n">s22</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">),</span> \
         <span class="n">h1</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span> \
         <span class="n">h2</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mf">0.4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0d01cffe68cc4a729711d1ac72449f86"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(s11, s12, s21, s22, h1, h2)&gt;
</pre></div>
</div>
</div>
</div>
<p>The more of these modules we add, the more complicated the shape of the output can be. When the width of the single <span class="math notranslate nohighlight">\(\mathrm{rect}\)</span>-functions approaches zero and the number of <span class="math notranslate nohighlight">\(\mathrm{rect}\)</span>-functions approaches infinity, any continuous function can be approximated.</p>
<p>This also holds for higher dimensions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">1.2</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">s1s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="n">s2s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">hs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">])</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s1s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span> <span class="o">+</span> <span class="n">rect_approx</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">s1s</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">s2s</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span><span class="n">res</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-8-ee7cdfff0621&gt;:2: RuntimeWarning: overflow encountered in exp
  return 1/(1+np.exp(-1*x))
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x1c88e130e50&gt;
</pre></div>
</div>
<img alt="_images/05_NeuralNetworksForCompImg_101_2.png" src="_images/05_NeuralNetworksForCompImg_101_2.png" />
</div>
</div>
<p>Although the theorem states that such a simple structure is enough to approximate any function, in practice network structures with more but thinner layers (i.e., with fewer building blocks) are employed as they can achieve similar results with notably fewer building blocks.</p>
</section>
<section id="optimization-of-network-parameters">
<h2>Optimization of network parameters<a class="headerlink" href="#optimization-of-network-parameters" title="Permalink to this headline">#</a></h2>
<p>How can we automatically determine the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> of the network so that <span class="math notranslate nohighlight">\(\forall (\mathbf{x},\mathbf{y}) \in \mathcal{T}:\text{dist}(\phi_\boldsymbol{\theta}(\mathbf{x}), \mathbf{y} ) \rightarrow \text{Min.}\,\)</span>?</p>
<section id="gradient-descent">
<h3>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">#</a></h3>
<p>To find this minimum, we compute the gradient <span class="math notranslate nohighlight">\(\nabla\text{dist}_\boldsymbol{\theta}\)</span> of the distance function <span class="math notranslate nohighlight">\(\text{dist}\)</span> with respect to the network parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p>
<p>We can then iteratively update an initial guess <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}_0\)</span> (e.g., random) of the network parameters by pushing it into the inverse direction of the gradient <span class="math notranslate nohighlight">\(\nabla\text{dist}_\boldsymbol{\theta}\)</span>, i.e., into the direction of the nearest minimum:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \hat{\boldsymbol{\theta}}_{i+1} \leftarrow \hat{\boldsymbol{\theta}}_{i} - \eta \nabla\text{dist}_\boldsymbol{\theta}(\phi_{\hat{\boldsymbol{\theta}_i}}(\mathbf{X}), \mathbf{Y} )\,, (\mathbf{X},\mathbf{Y}) \in \mathcal{T}
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\mathbf{X}, \mathbf{Y}\)</span> indicating batches of multiple training vectors <span class="math notranslate nohighlight">\((\mathbf{x}, \mathbf{y}) \in \mathcal{T}\)</span> and <span class="math notranslate nohighlight">\(\eta\)</span> denoting the so-called <em>learning rate</em> or the <em>step size</em> for the gradient descent updates.</p>
<ul class="simple">
<li><p>In every gradient descent iteration, the parameters are updated with regard to the respective batch of training samples <span class="math notranslate nohighlight">\((\mathbf{X}, \mathbf{Y})\)</span> chosen in that iteration.</p></li>
<li><p>In practical scenarios it is usually not possible to process the whole training set in one gradient descent step as the respective data would not fit into the available memory.</p></li>
<li><p>Hence, in every iteration another batch of training data is used, so that eventually all training samples have been used. The partitioning of <span class="math notranslate nohighlight">\(\mathcal{T}\)</span> into those batches is usually performed randomly. This is why this kind of gradient descent is sometimes referred to as <em>stochastic gradient descent</em>.</p></li>
<li><p>The set of gradient descent iterations needed to cycle through all training data once is a so-called <em>epoch</em>.</p></li>
</ul>
</section>
<section id="the-chain-rule-and-the-backpropagation-algorithm">
<h3>The chain rule and the backpropagation algorithm<a class="headerlink" href="#the-chain-rule-and-the-backpropagation-algorithm" title="Permalink to this headline">#</a></h3>
<p>Calculating the gradient required for gradient descent by hand can be infeasible for large expressions. Fortunately, this process can be automated as we will see in the following.</p>
<p>We start with an example.</p>
<p>Assume we want to calculate the derivative (i.e., the gradient) of <span class="math notranslate nohighlight">\(y = \log (x)^2\)</span> with respect to <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>We can express this function via intermediate variables for all basic math operations:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   y &amp;= v_2 \\
   v_2 &amp;= v_1^2 \\
   v_1 &amp;= \log (x) \,.
\end{align}\)</span></p>
<p>In order to find the derivate of <span class="math notranslate nohighlight">\(y\)</span> with respect to <span class="math notranslate nohighlight">\(x\)</span>, we can iteratively apply the chain rule to obtain:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \frac{\partial y}{\partial x} = \frac{\partial y}{\partial v_2} \frac{\partial v_2}{\partial x} = \frac{\partial y}{\partial v_2} \frac{\partial v_2}{\partial v_1} \frac{\partial v_1}{\partial x} \,.
\end{align}\)</span></p>
<p>Those partial derivatives can easily be obtained for the respective terms:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \frac{\partial y}{\partial v_2} &amp;= 1 \\
  \frac{\partial v_2}{\partial v_1} &amp;= 2v_1 \\
  \frac{\partial v_1}{\partial x} &amp;= \frac{1}{x}.
\end{align}\)</span></p>
<p>Hence, the sought derivate of <span class="math notranslate nohighlight">\(y\)</span> w.r.t. <span class="math notranslate nohighlight">\(x\)</span> is given by:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \frac{\partial y}{\partial x} = \frac{\partial y}{\partial v_2} \frac{\partial v_2}{\partial v_1} \frac{\partial v_1}{\partial x} = 1\cdot 2v_1 \cdot \frac{1}{x} \,.
\end{align}\)</span></p>
<p>This expression can be evaluated in reverse order (the so-called <em>backward pass</em>), i.e., from left to right, when the intermediate variables <span class="math notranslate nohighlight">\(v_2, v_1\)</span> have been evaluated for some <span class="math notranslate nohighlight">\(x\)</span> in the so-called <em>forward pass</em>.</p>
<p>When every basic mathematical function (e.g., <span class="math notranslate nohighlight">\(+, -, \exp, \log, \sin, \ldots\)</span>) also provides a method for the calculation of its gradient, the process of obtaining the derivative of an arbitrary complex expression, with respect to some variable and given the actual input numbers for the parameter(s), can be automated.</p>
<p>During the forward pass, a calculation graph is constructed that represents the hierarchical relations of the individual mathematical functions in terms of the chain rule. The intermediate results for every operation are saved in the nodes of this graph. Then, the graph can be traversed backwards starting from all leaves and intermediate gradient values can be calculated for every node and can then be backpropagated to the root yielding the sought gradient.</p>
<p>This approach is also known as the <em>backpropagation algorithm</em>.</p>
<section id="example-implementation-for-y-log-x-2">
<h4>Example implementation for <span class="math notranslate nohighlight">\(y = \log (x)^2\)</span><a class="headerlink" href="#example-implementation-for-y-log-x-2" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">square</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">inp</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">ln</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">square_grad</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
    <span class="n">inp</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">inp</span><span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">g</span>
    
<span class="k">def</span> <span class="nf">ln_grad</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
    <span class="n">inp</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">inp</span> <span class="o">*</span> <span class="n">out</span><span class="o">.</span><span class="n">g</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">v1</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">square</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span>
        
    <span class="n">v2</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">square_grad</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
    <span class="n">ln_grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">v2</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">g</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor(1.2069, dtype=torch.float64), tensor(0.7324, dtype=torch.float64))
</pre></div>
</div>
</div>
</div>
<p>Note: We just used PyTorch here so that we can easily introduce the property <code class="docutils literal notranslate"><span class="pre">.g</span></code> for all our variables.</p>
</section>
</section>
<section id="automatic-differentiation">
<h3>Automatic differentiation<a class="headerlink" href="#automatic-differentiation" title="Permalink to this headline">#</a></h3>
<p>There are various libraries that provide the functionality of backpropagation mentioned above without the user (i.e., the programmer) having to explicitly control it. Often a technique called <em>operator overloading</em> is employed that builds the computation graph required for the gradient calculation behind the scenes.</p>
<p>In PyTorch, calculating the gradient of our equation <span class="math notranslate nohighlight">\(y = \log (x)^2\)</span> w.r.t. <span class="math notranslate nohighlight">\(x\)</span> could be achieved like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definition of our function using torch-routines:</span>
<span class="k">def</span> <span class="nf">y_torch</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>    <span class="c1"># Our input variable</span>
<span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>   <span class="c1"># We need the gradient with respect to x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">y_torch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># Forward pass</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>        <span class="c1"># Backward pass</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>                   <span class="c1"># Access the gradient</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.7324)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="architectures-and-loss-functions">
<h2>Architectures and loss functions<a class="headerlink" href="#architectures-and-loss-functions" title="Permalink to this headline">#</a></h2>
<p>During the past 10 years, several multi purpose neural network architectures (or architectural building blocks) have been proposed, which we will discover in the following paragraphs.</p>
<p>Depending on the task a neural network has to perform, i.e., the function it should approximate, appropriate architectures and suitable distance functions <span class="math notranslate nohighlight">\(\mathrm{dist}\)</span>, so-called <em>loss functions</em> <span class="math notranslate nohighlight">\(\ell\)</span> for the training, have to be chosen.</p>
<section id="deep-convolutional-networks-for-image-classification">
<h3>Deep convolutional networks for image classification<a class="headerlink" href="#deep-convolutional-networks-for-image-classification" title="Permalink to this headline">#</a></h3>
<p>In image classification tasks the neural network is supposed to assign a single class label <span class="math notranslate nohighlight">\(y\)</span> to a given input image <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, e.g. , the result could be a description of the scene visible in the image (e.g., a kitchen).</p>
<p>Hence, typical image classification architectures successively decrease the input’s spatial resolution while increasing the channel resolution.</p>
<p>A prominent example are so-called <em>VGG neural networks</em> developed at the Visual Geometry Group (VGG) at University of Oxford by Karen Simonyan and Andrew Zisserman (see <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>).</p>
<p>The architecture looks as follows:</p>
<img src="figures/5/VGG_architecture.svg" style="max-height:40vh"><section id="cross-entropy-loss">
<h4>Cross-entropy loss<a class="headerlink" href="#cross-entropy-loss" title="Permalink to this headline">#</a></h4>
<p>The so-called <em>cross-entropy loss</em> is a common loss function for (image) classification scenarios.</p>
<p>When the final layer of a classification neural network yields a vector <span class="math notranslate nohighlight">\(\mathbf{y} \in [0,1]^C\)</span> of probabilities for all <span class="math notranslate nohighlight">\(C\)</span> possible classes (e.g., obtained via a final softmax layer) and <span class="math notranslate nohighlight">\(i \in [1,C]\)</span> represents the index of the correct class, the cross-entropy loss is calculated via:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \ell_\mathrm{cross} = -\log (y_i) \,.
\end{align}\)</span></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some libraries (e.g., PyTorch), the implementation of the cross-entropy loss automatically applies softmax to its input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> enforcing that all elements <span class="math notranslate nohighlight">\(x_i\leq1\)</span> and <span class="math notranslate nohighlight">\(\sum_i x_i=1\)</span>.</p>
</div>
</section>
</section>
<section id="residual-nets-skip-connections">
<h3>Residual nets / skip connections<a class="headerlink" href="#residual-nets-skip-connections" title="Permalink to this headline">#</a></h3>
<p>In 2016, Kaiming He et al. proposed in their paper <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">Deep Residual Learning for Image Recognition</a> to repeatedly introduce so-called <em>skip connections</em> which add the output of some layer to the output of a deeper layer as visualized in the following figure:</p>
<img src="figures/5/residual_block.svg" style="max-height:40vh"><p>It has been shown, that employing this design principle makes networks easier to train and hence enables architectures with more layers.</p>
<p>Intuitively, one could imagine the case where the network should learn the identity function at some layer, i.e., <span class="math notranslate nohighlight">\(\mathcal{F}(\mathbf{x}) = \mathbf{x}\)</span>. By means of a residual block, it could simply learn <span class="math notranslate nohighlight">\(\mathcal{F}(\mathbf{x}) = \mathbf{0}\)</span> and the skip connection would yield <span class="math notranslate nohighlight">\(\mathcal{F}(\mathbf{x}) + \mathbf{x} = \mathbf{0} + \mathbf{x} = \mathbf{x}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sometimes, skip connections need to increase the dimension of the input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> so that it matches the dimension of <span class="math notranslate nohighlight">\(\mathcal{F}(\mathbf{x})\)</span>. This can be done by appending zeros (<em>zero padding</em>) or by a learned linear projection.</p>
</div>
</section>
<section id="encoder-decoder-modules">
<h3>Encoder / decoder modules<a class="headerlink" href="#encoder-decoder-modules" title="Permalink to this headline">#</a></h3>
<p>The concept of so-called <em>encoders</em> and <em>decoders</em> is quite versatile and can be employed in different scenarios. As the names suggest, an encoder transforms the input into another, usually significantly lower dimensional space, the so-called <em>latent space</em>, and the decoder tries to reconstruct the original input based on the output of the encoder as precisely as possible.</p>
<p>When used in concert as just described, such pairs of encoders and decoders are also called <em>auto encoders</em>.</p>
<p>During training, usually the reconstruction loss, i.e., a pixel-wise mean squared error between the input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and the reconstruction <span class="math notranslate nohighlight">\(\hat{\mathbf{x}}\)</span> is minimized.</p>
<p>The following figure visualizes the concept:</p>
<img src="figures/5/encoder_decoder.svg" style="max-height:40vh"><p>Encoders usually involve multiple convolutional and pooling layers to reduce the spatial dimension, whereas decoders heavily rely on transposed convolutions and upsampling layers to increase spatial resolution.</p>
<p>The latent representation of the input can be exploited in various ways, e.g.:</p>
<ul class="simple">
<li><p>as a compression of the input to reduce the necessary amount of data or</p></li>
<li><p>to perform denoising, inverse filtering etc. and</p></li>
<li><p>to synthesize new images from the domain of the input data by drawing random vectors in the latent space and by feeding them into the decoder.</p></li>
</ul>
<section id="mean-squared-error-loss">
<h4>Mean squared error loss<a class="headerlink" href="#mean-squared-error-loss" title="Permalink to this headline">#</a></h4>
<p>A straight forward choice of a loss function for such image-to-image-tasks is the <em>mean squared error (MSE) loss</em>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \ell_\mathrm{MSE} = \frac{1}{N} \left\| \mathbf{Y} - \phi (\mathbf{X}) \right\|^2_2 \,,
\end{align}\)</span></p>
<p>for a given batch <span class="math notranslate nohighlight">\((\mathbf{X},\mathbf{Y}) \in \mathcal{T}\)</span> of training samples and the total number <span class="math notranslate nohighlight">\(N\)</span> of elements in <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>.</p>
</section>
<section id="anomaly-detection-for-visual-inspection">
<h4>Anomaly detection for visual inspection<a class="headerlink" href="#anomaly-detection-for-visual-inspection" title="Permalink to this headline">#</a></h4>
<p>As the latent representation focuses its limited amount of information on the significant and important aspects of the input images, it usually does not allow to reconstruct fine image details, e.g., like scratches. This can be exploited to detect such material defects by calculating the pixel-wise difference between the reconstruction <span class="math notranslate nohighlight">\(\hat{\mathbf{x}}\)</span> and the input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
</section>
<section id="variational-auto-encoders">
<h4>Variational auto encoders<a class="headerlink" href="#variational-auto-encoders" title="Permalink to this headline">#</a></h4>
<p>The loss function used during the training of variational auto encoders includes a second term besides the reconstruction loss that forces the distribution of the latent representations to follow a normal distribution.</p>
<p>This usually yields better synthesis performance when using the decoder on random samples drawn from the latent space.</p>
</section>
</section>
<section id="u-net-for-segmentation-or-regression-tasks">
<h3>U-Net for segmentation or regression tasks<a class="headerlink" href="#u-net-for-segmentation-or-regression-tasks" title="Permalink to this headline">#</a></h3>
<p>Named after its macroscopic shape which looks like the letter U, the so-called <em>U-Net</em> is a neural network mainly based on convolutional layers that performs a pixel-wise regression. This means that the network consumes images and yields images of the same size with updated pixel values.</p>
<p>The U-Net has been introduced by Olaf Ronneberger et al. in 2015 (see <a class="reference external" href="http://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>).</p>
<p>Its main use case is the pixel-wise segmentation of images (i.e., assigning individual class labels to every pixel), however it has also been employed for various other tasks as we will learn later on.</p>
<img src="figures/5/u-net.svg" style="max-height:80vh"></section>
</section>
<section id="example-applications">
<h2>Example applications<a class="headerlink" href="#example-applications" title="Permalink to this headline">#</a></h2>
<section id="denoising-with-neural-networks">
<h3>Denoising with neural networks<a class="headerlink" href="#denoising-with-neural-networks" title="Permalink to this headline">#</a></h3>
<p>For solving the problem of denoising we want a neural network <span class="math notranslate nohighlight">\(\phi\)</span> to approximate a function that takes a noisy input image <span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{i} + \mathbf{n}\)</span> and yields the image <span class="math notranslate nohighlight">\(\mathbf{i}\)</span> without the noise <span class="math notranslate nohighlight">\(\mathbf{n}\)</span>:</p>
<img src="figures/5/dnn_denoising.svg" style="max-height:40vh"><p>Apparently, the input and output dimensions of this network have to match, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{dim}\, \mathbf{x} = \mathrm{dim}\, \phi(\mathbf{x})\,.
\end{align}\)</span></p>
<p>Furthermore, the input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> represents an image with pixel values and the output <span class="math notranslate nohighlight">\(\phi (\mathbf{x})\)</span> is again an image with pixel values.</p>
<p>Such a problem to be solved by a neural network, where the output values are continuous, is called a <em>regression problem</em>.</p>
<p>Although it might be tempting to create a network that directly encodes the mapping from noisy to clear images, there is another way that showed to be easier to train and to yield better results:</p>
<ul class="simple">
<li><p>Train <span class="math notranslate nohighlight">\(\phi\)</span> to estimate the noise <span class="math notranslate nohighlight">\(\mathbf{n}\)</span> of the input <span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{i} + \mathbf{n}\)</span>, i.e., <span class="math notranslate nohighlight">\(\phi(\mathbf{x}) = \hat{\mathbf{n}}\)</span>,</p></li>
</ul>
<ul class="simple">
<li><p>then calculate an estimate of the sought noise-free image <span class="math notranslate nohighlight">\(\hat{\mathbf{i}} = \mathbf{x} - \hat{\mathbf{n}}\)</span>.</p></li>
</ul>
<p>This has been done by Kai Zhang et al. (see <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/7839189">Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising</a>):</p>
<img src="figures/5/residual_learning_denoising.svg" style="max-height:40vh"><ul class="simple">
<li><p>Another advantage of this method by Zhang is the lack of fully connected layers. This enables that the neural network can be applied to any input size since there are no input size-dependent parameterized structures involved.</p></li>
</ul>
</section>
<section id="learned-image-signal-processing-unit">
<h3>Learned image signal processing unit<a class="headerlink" href="#learned-image-signal-processing-unit" title="Permalink to this headline">#</a></h3>
<p>See the paper <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Learning_to_See_CVPR_2018_paper.pdf">Learning to See in the Dark</a> by Chen Chen et al.</p>
</section>
<section id="learned-optics-for-single-shot-high-dynamic-range-imaging">
<h3>Learned optics for single-shot high-dynamic-range imaging<a class="headerlink" href="#learned-optics-for-single-shot-high-dynamic-range-imaging" title="Permalink to this headline">#</a></h3>
<p>See the paper <a class="reference external" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Metzler_Deep_Optics_for_Single-Shot_High-Dynamic-Range_Imaging_CVPR_2020_paper.pdf">Deep Optics for Single-shot High-dynamic-range Imaging</a> by Metzler et al.</p>
</section>
</section>
<section id="tools-libraries-and-reading-resources">
<h2>Tools, libraries and reading resources<a class="headerlink" href="#tools-libraries-and-reading-resources" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/">PyTorch</a> famous Python library for neural network development.</p></li>
<li><p><a class="reference external" href="https://www.fast.ai/">FastAI</a> high-level API for PyTorch, very informative free online course, book.</p></li>
</ul>
</section>
</section>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"38bb7eb9fcb54b5f8aa1afc59c38597b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "76b54270a5344c0aa64f84847f680750": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "dfdb99822e2141f586128cfc02037176": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "w", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_38bb7eb9fcb54b5f8aa1afc59c38597b", "max": 200.0, "min": 1.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 1.0, "style": "IPY_MODEL_76b54270a5344c0aa64f84847f680750", "value": 8.0}}, "2e4ade2b98014efbad5381c7de392b64": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "78cfe88a99a84dd49121e90a0f147564": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "225cc752423145118f8317253c77c5d3": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "b", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_2e4ade2b98014efbad5381c7de392b64", "max": 100.0, "min": -100.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 1.0, "style": "IPY_MODEL_78cfe88a99a84dd49121e90a0f147564", "value": -4.0}}, "461c62c223a1417cbc91f94a5af8edf7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ca8680b4d62043f9944ad51d902f445a": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_dfdb99822e2141f586128cfc02037176", "IPY_MODEL_225cc752423145118f8317253c77c5d3", "IPY_MODEL_c3163630f3884316b97b211f20d04316"], "layout": "IPY_MODEL_461c62c223a1417cbc91f94a5af8edf7"}}, "508db22875a449ed9954190c433e507b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c3163630f3884316b97b211f20d04316": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_508db22875a449ed9954190c433e507b", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {"needs_background": "light"}, "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}}]}}, "22750d021178463399049ddb51302cb4": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8b7492e193d745d8a249b66a1ab96dc7": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "09fb8eed7d85454e8ec796c58b7f041b": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "i", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_22750d021178463399049ddb51302cb4", "max": 5, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_8b7492e193d745d8a249b66a1ab96dc7", "value": 5}}, "f0493eddef674341aeac22d6dd1c0160": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8fa28092c3f74aaa8e8602bce9430263": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_09fb8eed7d85454e8ec796c58b7f041b", "IPY_MODEL_67dcae5f74324760845a9e7eda8a4732"], "layout": "IPY_MODEL_f0493eddef674341aeac22d6dd1c0160"}}, "78ba11c0a1de4c93b6ec44965cdb22c7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "67dcae5f74324760845a9e7eda8a4732": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_78ba11c0a1de4c93b6ec44965cdb22c7", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<img src=\"figures/5/pooling_layer_5.svg\" style=\"max-height:50vh\"/>"}}]}}, "82e3e76964b7481fa36e57217fc8828e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "dd389da6a2e8430991f299ad32823de5": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "19b3ac244684443ebecf752c4df9f6be": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "i", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_82e3e76964b7481fa36e57217fc8828e", "max": 5, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_dd389da6a2e8430991f299ad32823de5", "value": 5}}, "854c253fd0024a9f97e1281120200eef": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "90b7ad9ea50c415cbe7ae92b5b8be6d6": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_19b3ac244684443ebecf752c4df9f6be", "IPY_MODEL_e933bc0beaf14a5cbf18a154da8b0069"], "layout": "IPY_MODEL_854c253fd0024a9f97e1281120200eef"}}, "c72e3fa21c5544ccb5b87f8ad5b684e6": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e933bc0beaf14a5cbf18a154da8b0069": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c72e3fa21c5544ccb5b87f8ad5b684e6", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<img src=\"figures/5/convolutional_layer_5.svg\" style=\"max-height:50vh\"/>"}}]}}, "f1af77a377294113b15594c439a7b87e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e408465d18094576ba73ffeb72bf6fe1": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "98cfafd45a3748f68a685cf55fd46e3a": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "i", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_f1af77a377294113b15594c439a7b87e", "max": 3, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_e408465d18094576ba73ffeb72bf6fe1", "value": 3}}, "833a6e96ff9845a88520bd82712aed40": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a559380a9502488085fcfa2862711755": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_98cfafd45a3748f68a685cf55fd46e3a", "IPY_MODEL_1d5bc941daac4167831e82ed3c4888f4"], "layout": "IPY_MODEL_833a6e96ff9845a88520bd82712aed40"}}, "be23fc0c520645ae85396460e9a5dc35": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1d5bc941daac4167831e82ed3c4888f4": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_be23fc0c520645ae85396460e9a5dc35", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<img src=\"figures/5/transposed_convolutional_layer_3.svg\" style=\"max-height:50vh\"/>"}}]}}, "df20ee1bd6d94913a868bb2127911a2f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "58fc3645085c45f685b4bbaebb079aa5": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "f3939ef410884713821d97ad6d8b7795": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "s1", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_df20ee1bd6d94913a868bb2127911a2f", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_58fc3645085c45f685b4bbaebb079aa5", "value": 0.2}}, "58160177ae184fd2adb9100d59be62b4": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "106fff54588546f0872be7a9e1d247dd": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "e2ae40ced5bb46a4b1f140b896e66379": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "s2", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_58160177ae184fd2adb9100d59be62b4", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_106fff54588546f0872be7a9e1d247dd", "value": 0.6}}, "c5d6d9a5922c47c88f90cae09a882dbe": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9c8f94b6d5744c109bc31e0880a16ba3": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "da3da157da6947b38956e8b9b88bf831": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "w1", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_c5d6d9a5922c47c88f90cae09a882dbe", "max": 2.0, "min": -2.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_9c8f94b6d5744c109bc31e0880a16ba3", "value": 0.4}}, "1c2cdc78568c40a095ce9109abc3d91a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a0c2fdde99c9492db5ebb917c506e248": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "b5cbccb0dfec455e8ad96b1871479227": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "w2", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_1c2cdc78568c40a095ce9109abc3d91a", "max": 2.0, "min": -2.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_a0c2fdde99c9492db5ebb917c506e248", "value": 0.6}}, "f0f00e95fccb498893a5cbe25dc77929": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "358e1f7856ff4ec6a19513bc08d74f7a": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_f3939ef410884713821d97ad6d8b7795", "IPY_MODEL_e2ae40ced5bb46a4b1f140b896e66379", "IPY_MODEL_da3da157da6947b38956e8b9b88bf831", "IPY_MODEL_b5cbccb0dfec455e8ad96b1871479227", "IPY_MODEL_e0c7fe154c3646ba9ad78f25d2a5f4c2"], "layout": "IPY_MODEL_f0f00e95fccb498893a5cbe25dc77929"}}, "5062be0170ba4451ba96d433f9b45bb4": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e0c7fe154c3646ba9ad78f25d2a5f4c2": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_5062be0170ba4451ba96d433f9b45bb4", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {"needs_background": "light"}, "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}}]}}, "be138b4a753d4b1cb788a7da8f68b8d0": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bd0465b08220451999346fbd9d212e70": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "1b0583b7f44d4c5a93408ab43b0fe4e2": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "s11", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_be138b4a753d4b1cb788a7da8f68b8d0", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_bd0465b08220451999346fbd9d212e70", "value": 0.2}}, "3e63cd33b2eb40f9a799ab596d8a8f6c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ae11dc3c2bc240ac8033488f79ddd301": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "c73b407cf8bc4ca28a137b483b6e6d71": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "s12", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_3e63cd33b2eb40f9a799ab596d8a8f6c", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_ae11dc3c2bc240ac8033488f79ddd301", "value": 0.3}}, "a0e869234a52409fa42aba9dc07d6156": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5c85a0652ec24ddfab4dabe31907004a": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "9b52c0a0e9bc451891f36eaadbc24c58": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "s21", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_a0e869234a52409fa42aba9dc07d6156", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_5c85a0652ec24ddfab4dabe31907004a", "value": 0.4}}, "6e64496835bc40e8846160dd57db4a45": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b7946159fe1d48eca1467b76ce6adccc": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "28a927f9157d448eb27c9d808c55099e": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "s22", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_6e64496835bc40e8846160dd57db4a45", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_b7946159fe1d48eca1467b76ce6adccc", "value": 0.6}}, "8110ed66677a48f2ae8a1143384edba5": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c9572d5c7a7e46eeb997971dba79e00f": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "9a9c592fdcd2496199be6d31fb188a93": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "h1", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_8110ed66677a48f2ae8a1143384edba5", "max": 2.0, "min": -2.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_c9572d5c7a7e46eeb997971dba79e00f", "value": 0.3}}, "95fcf255f8a641039d5c1f85aebf12ce": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5f2faefbee8144b2bc72569723de320f": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "9d33199fed9c40ffa905828929eea92d": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "h2", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_95fcf255f8a641039d5c1f85aebf12ce", "max": 2.0, "min": -2.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_5f2faefbee8144b2bc72569723de320f", "value": -0.4}}, "2e062c031df8464cb0ba088d09c2bd23": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0d01cffe68cc4a729711d1ac72449f86": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_1b0583b7f44d4c5a93408ab43b0fe4e2", "IPY_MODEL_c73b407cf8bc4ca28a137b483b6e6d71", "IPY_MODEL_9b52c0a0e9bc451891f36eaadbc24c58", "IPY_MODEL_28a927f9157d448eb27c9d808c55099e", "IPY_MODEL_9a9c592fdcd2496199be6d31fb188a93", "IPY_MODEL_9d33199fed9c40ffa905828929eea92d", "IPY_MODEL_88b2b600dda444dfb3407a867eaa9e46"], "layout": "IPY_MODEL_2e062c031df8464cb0ba088d09c2bd23"}}, "bbe720508d3345168e8bab7b2d4fb5ae": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "88b2b600dda444dfb3407a867eaa9e46": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_bbe720508d3345168e8bab7b2d4fb5ae", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {"needs_background": "light"}, "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}}]}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "compimg"
        },
        kernelOptions: {
            kernelName: "compimg",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'compimg'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="04_LightTransportAnalysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Light Transport Analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="06_InverseProblemsInCompimg.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Inverse Problems in Computational Imaging</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Dr.-Ing. Johannes Meyer<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>