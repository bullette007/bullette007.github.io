
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Inverse Problems in Computational Imaging &#8212; Computational Imaging - Course Notes</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Neural Networks for Computational Imaging" href="05_NeuralNetworksForCompImg.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Computational Imaging - Course Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Computational Imaging - Course Notes for Winter Term 2022 / 2023
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_Introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_Basics.html">
   Fundamental Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_LightFieldMethods.html">
   Light Field Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_LightTransportAnalysis.html">
   Light Transport Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_NeuralNetworksForCompImg.html">
   Neural Networks for Computational Imaging
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Inverse Problems in Computational Imaging
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/06_InverseProblemsInCompimg.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="_sources/06_InverseProblemsInCompimg.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#content">
   Content
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-into-inverse-problems">
   Introduction into inverse problems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-denoising">
   Image denoising
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-a-posteriori-map-solution">
     Maximum a-posteriori (MAP) solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#general-linear-inverse-problems">
   General linear inverse problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-perspective-of-inverse-problems">
     Bayesian perspective of inverse problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#total-variation">
     Total Variation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-deconvolution">
   Image deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#duality-between-signal-processing-perspective-and-algebraic-perspective">
     Duality between signal processing perspective and algebraic perspective
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inverse-filter-for-deconvolution">
   Inverse filter for deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-inverse-filter-reconstruction-results-for-increasing-noise-levels">
     Example inverse filter reconstruction results for increasing noise levels
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wiener-filter-for-deconvolution">
   Wiener filter for deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-wiener-filter-reconstruction-results-for-increasing-noise-levels-with-snr-heuristics">
     Example Wiener filter reconstruction results for increasing noise levels with SNR-heuristics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#richardson-lucy-deconvolution">
   Richardson-Lucy deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiplicative-version-of-the-richardson-lucy-algorithm">
     Multiplicative version of the Richardson-Lucy algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comments-on-the-richardson-lucy-algorithm">
       Comments on the Richardson-Lucy algorithm
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#half-quadratic-splitting-hqs-method">
   Half-quadratic splitting (HQS) method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#excursion-on-proximal-operators">
     Excursion on proximal operators
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#definition-of-a-proximal-operator">
       Definition of a proximal operator
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interpretation-of-proximal-operators">
       Interpretation of proximal operators
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hqs-for-deconvolution">
     HQS for deconvolution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hqs-with-total-variation-and-denoising-regularizers">
       HQS with total variation and denoising regularizers
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-implementation-of-x-update">
         Efficient implementation of
         <span class="math notranslate nohighlight">
          \(x\)
         </span>
         -update
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#special-case-of-total-variation-regularizer">
         Special case of total variation regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#general-regularizer">
         General regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-implementation-of-z-update-for-anisotropic-tv-regularizer">
         Efficient implementation of
         <span class="math notranslate nohighlight">
          \(z\)
         </span>
         -update for anisotropic TV regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#visualization-of-soft-thresholding-operator">
         Visualization of soft thresholding operator
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-implementation-of-z-update-for-isotropic-tv-regularizer">
         Efficient implementation of
         <span class="math notranslate nohighlight">
          \(z\)
         </span>
         -update for isotropic TV regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-update-of-mathbf-z-in-general-case">
         Efficient update of
         <span class="math notranslate nohighlight">
          \(\mathbf{z}\)
         </span>
         in general case
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hqs-for-general-linear-inverse-problems">
     HQS for general linear inverse problems
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#derivation-of-mathbf-x-update-for-hqs-for-general-linear-inverse-problems">
       Derivation of
       <span class="math notranslate nohighlight">
        \(\mathbf{x}\)
       </span>
       -update for HQS for general linear inverse problems
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problems-of-hqs">
     Problems of HQS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternating-direction-method-of-multipliers-admm">
   Alternating direction method of multipliers (ADMM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mathbf-x-update">
     The
     <span class="math notranslate nohighlight">
      \(\mathbf{x}\)
     </span>
     -update:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mathbf-z-update">
     The
     <span class="math notranslate nohighlight">
      \(\mathbf{z}\)
     </span>
     -update:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-snr-estimation-for-wiener-filtering">
   Deep SNR-estimation for Wiener filtering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-wiener-filter-reconstruction-results-with-deep-snr-estimation">
     Example Wiener filter reconstruction results with deep SNR-estimation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantitative-results">
     Quantitative results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unrolled-optimization">
   Unrolled optimization
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Inverse Problems in Computational Imaging</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#content">
   Content
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-into-inverse-problems">
   Introduction into inverse problems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-denoising">
   Image denoising
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-a-posteriori-map-solution">
     Maximum a-posteriori (MAP) solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#general-linear-inverse-problems">
   General linear inverse problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-perspective-of-inverse-problems">
     Bayesian perspective of inverse problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#total-variation">
     Total Variation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-deconvolution">
   Image deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#duality-between-signal-processing-perspective-and-algebraic-perspective">
     Duality between signal processing perspective and algebraic perspective
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inverse-filter-for-deconvolution">
   Inverse filter for deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-inverse-filter-reconstruction-results-for-increasing-noise-levels">
     Example inverse filter reconstruction results for increasing noise levels
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wiener-filter-for-deconvolution">
   Wiener filter for deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-wiener-filter-reconstruction-results-for-increasing-noise-levels-with-snr-heuristics">
     Example Wiener filter reconstruction results for increasing noise levels with SNR-heuristics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#richardson-lucy-deconvolution">
   Richardson-Lucy deconvolution
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiplicative-version-of-the-richardson-lucy-algorithm">
     Multiplicative version of the Richardson-Lucy algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comments-on-the-richardson-lucy-algorithm">
       Comments on the Richardson-Lucy algorithm
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#half-quadratic-splitting-hqs-method">
   Half-quadratic splitting (HQS) method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#excursion-on-proximal-operators">
     Excursion on proximal operators
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#definition-of-a-proximal-operator">
       Definition of a proximal operator
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interpretation-of-proximal-operators">
       Interpretation of proximal operators
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hqs-for-deconvolution">
     HQS for deconvolution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hqs-with-total-variation-and-denoising-regularizers">
       HQS with total variation and denoising regularizers
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-implementation-of-x-update">
         Efficient implementation of
         <span class="math notranslate nohighlight">
          \(x\)
         </span>
         -update
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#special-case-of-total-variation-regularizer">
         Special case of total variation regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#general-regularizer">
         General regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-implementation-of-z-update-for-anisotropic-tv-regularizer">
         Efficient implementation of
         <span class="math notranslate nohighlight">
          \(z\)
         </span>
         -update for anisotropic TV regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#visualization-of-soft-thresholding-operator">
         Visualization of soft thresholding operator
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-implementation-of-z-update-for-isotropic-tv-regularizer">
         Efficient implementation of
         <span class="math notranslate nohighlight">
          \(z\)
         </span>
         -update for isotropic TV regularizer
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#efficient-update-of-mathbf-z-in-general-case">
         Efficient update of
         <span class="math notranslate nohighlight">
          \(\mathbf{z}\)
         </span>
         in general case
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hqs-for-general-linear-inverse-problems">
     HQS for general linear inverse problems
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#derivation-of-mathbf-x-update-for-hqs-for-general-linear-inverse-problems">
       Derivation of
       <span class="math notranslate nohighlight">
        \(\mathbf{x}\)
       </span>
       -update for HQS for general linear inverse problems
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problems-of-hqs">
     Problems of HQS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternating-direction-method-of-multipliers-admm">
   Alternating direction method of multipliers (ADMM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mathbf-x-update">
     The
     <span class="math notranslate nohighlight">
      \(\mathbf{x}\)
     </span>
     -update:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-mathbf-z-update">
     The
     <span class="math notranslate nohighlight">
      \(\mathbf{z}\)
     </span>
     -update:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-snr-estimation-for-wiener-filtering">
   Deep SNR-estimation for Wiener filtering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-wiener-filter-reconstruction-results-with-deep-snr-estimation">
     Example Wiener filter reconstruction results with deep SNR-estimation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantitative-results">
     Quantitative results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unrolled-optimization">
   Unrolled optimization
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><span class="math notranslate nohighlight">\(\begin{align}
  \newcommand{transp}{^\intercal}
  \newcommand{F}{\mathcal{F}}
  \newcommand{Fi}{\mathcal{F}^{-1}}
  \newcommand{inv}{^{-1}}
  \newcommand{stochvec}[1]{\mathbf{\tilde{#1}}}
  \newcommand{argmax}[1]{\underset{#1}{\mathrm{arg\, max}}}
  \newcommand{argmin}[1]{\underset{#1}{\mathrm{arg\, min}}}
\end{align}\)</span></p>
<p><font size="7"> Computational Imaging </font><br><br><br></p>
<section class="tex2jax_ignore mathjax_ignore" id="inverse-problems-in-computational-imaging">
<h1>Inverse Problems in Computational Imaging<a class="headerlink" href="#inverse-problems-in-computational-imaging" title="Permalink to this headline">#</a></h1>
<section id="content">
<h2>Content<a class="headerlink" href="#content" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Introduction into inverse problems</p></li>
<li><p>Image denoising</p></li>
<li><p>General linear inverse problems</p></li>
<li><p>Image deconvolution</p></li>
<li><p>Inverse filter for deconvolution</p></li>
<li><p>Wiener filter for deconvolution</p></li>
<li><p>Richardson-Lucy deconvolution</p></li>
<li><p>Half-quadratic splitting method</p></li>
<li><p>Alternating direction method of multipliers</p></li>
<li><p>Deep SNR-estimation for Wiener filtering</p></li>
<li><p>Unrolled optimization</p></li>
</ul>
</section>
<section id="introduction-into-inverse-problems">
<h2>Introduction into inverse problems<a class="headerlink" href="#introduction-into-inverse-problems" title="Permalink to this headline">#</a></h2>
<p>An <em>inverse problem</em> represents the task of finding the input values to some function or process that produced certain output values which have been observed. Such problems are called <em>inverse</em>, as they start with the output and have the goal of finding the corresponding input.</p>
<p>Unfortunately, inverse problems often represent so-called <em>ill-posed problems</em>. A problem is considered to be ill-posed if one of the following properties holds:</p>
<ul class="simple">
<li><p>There is no solution to the problem,</p></li>
<li><p>there is no unique solution, i.e., there are multiple possible inputs that explain the observed data,</p></li>
<li><p>the solution does not change continuously w.r.t. to changes of the output.</p></li>
</ul>
<p>A common approach to mitigate the difficulties involved with ill-posed inverse problems is to employ so-called <em>regularization methods</em> which usually use prior knowledge about the sought solution to guide the reconstruction process into the right direction.</p>
</section>
<section id="image-denoising">
<h2>Image denoising<a class="headerlink" href="#image-denoising" title="Permalink to this headline">#</a></h2>
<p>The goal of image denoising it to recover an original image <span class="math notranslate nohighlight">\(s(\mathbf{x})\)</span> after is has been affected by additive, signal-independent noise <span class="math notranslate nohighlight">\(n(\mathbf{x})\)</span>, which is a common general assumption for noise present in digitally acquired images:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   g(\mathbf{x}) = s(\mathbf{x}) + n(\mathbf{x}) \,.
\end{align}\)</span></p>
<p>Note: The dependence on a spatial variable (e.g., like <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> for <span class="math notranslate nohighlight">\(g(\mathbf{x})\)</span>) is omitted for this chapter for the sake of clarity.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The dependence on a spatial variable (e.g., like <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> for <span class="math notranslate nohighlight">\(g(\mathbf{x})\)</span>) is omitted for this chapter for the sake of clarity.</p>
</div>
<ul class="simple">
<li><p>The pixel-wise noise <span class="math notranslate nohighlight">\(n_i\)</span> follows a zero-mean i.i.d. normal distribution, i.e., <span class="math notranslate nohighlight">\(n_i \sim \mathcal{N}(0, \sigma ^2)\)</span> and</p></li>
<li><p>the pixel <span class="math notranslate nohighlight">\(s_i\)</span> of the undistorted image follow an i.i.d. normal distribution with zero variance, i.e., <span class="math notranslate nohighlight">\(s_i \sim \mathcal{N}(s_i, 0)\)</span>.</p></li>
<li><p>Hence, the pixel <span class="math notranslate nohighlight">\(g_i\)</span> of the observed image can be modelled via the sum of the two normal distributions, i.e., <span class="math notranslate nohighlight">\(g_i \sim \mathcal{N}(s_i, \sigma^2)\)</span>.</p></li>
</ul>
<p>The per-pixel distribution of <span class="math notranslate nohighlight">\(g\)</span> is given by</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   p(g_i \vert s_i, \sigma ) = \frac{1}{\sqrt{2\pi\sigma^2}} \mathrm{e}^{-\frac{(g_i - s_i)^2}{2\sigma^2}} \,.
\end{align}\)</span></p>
<p>Due to the pixel-wise independence of the involved probabilities, the joint probability of the whole image is given by the product of the individual probabilities:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   p(\mathbf{g}\vert \mathbf{s}, \sigma) = \prod\limits_i p(g_i\vert s_i, \sigma) \propto \mathrm{e}^{-\frac{\left\| \mathbf{g} - \mathbf{s} \right\|^2_2 }{2\sigma^2}} \,.
\end{align}\)</span></p>
<p>Bayes’ rule yields the posterior distribution for the sought undistorted image <span class="math notranslate nohighlight">\(\mathbf{s}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   p(\mathbf{s} \vert \mathbf{g}, \sigma) = \frac{p(\mathbf{g}\vert \mathbf{s}, \sigma) p(\mathbf{s})}{p(\mathbf{g})} \propto p(\mathbf{g}\vert \mathbf{s}, \sigma) p(\mathbf{s})\,,
\end{align}\)</span></p>
<p>with the a priori probability <span class="math notranslate nohighlight">\(p(\mathbf{s})\)</span> of the sought image <span class="math notranslate nohighlight">\(\mathbf{s}\)</span>.</p>
<section id="maximum-a-posteriori-map-solution">
<h3>Maximum a-posteriori (MAP) solution<a class="headerlink" href="#maximum-a-posteriori-map-solution" title="Permalink to this headline">#</a></h3>
<p>The maximum a-posteriori (MAP) estimate of <span class="math notranslate nohighlight">\( \mathbf{s}\)</span> can be obtained by maximizing (minimizing) the (negative) natural logarithm of the posterior distribution:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \hat{\mathbf{s}}_\mathrm{MAP} &amp;= \argmin{\mathbf{s}}\, -\log \left( p(\mathbf{s} \vert \mathbf{g}, \sigma) \right) \\
   &amp;= \argmin{\mathbf{s}}\, - \log p(\mathbf{g}\vert \mathbf{s}, \sigma) - \log p(\mathbf{s}) \\
   &amp;= \argmin{\mathbf{s}}\, \frac{1}{2\sigma^2}\left\| \mathbf{g} - \mathbf{s} \right\|^2_2 - \log p(\mathbf{s}) \\
   &amp;= \argmin{\mathbf{s}}\, \frac{1}{2\sigma^2}\left\| \mathbf{g} - \mathbf{s} \right\|^2_2 + \Gamma (\mathbf{s}) \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\Gamma(\mathbf{s})\)</span> denoting the negative natural logarithm of the prior on <span class="math notranslate nohighlight">\(\mathbf{s}\)</span>.</p>
<p>If no information about the prior <span class="math notranslate nohighlight">\(p(\mathbf{s})\)</span> is exploited, every pixel value has to be considered equally likely, i.e., <span class="math notranslate nohighlight">\(p(s_i) = 1\)</span>, resulting in a trivial but useless solution for the estimate of <span class="math notranslate nohighlight">\(\mathbf{s}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \hat{\mathbf{s}}_\mathrm{flat\ prior} = \argmin{\mathbf{s}}\, \frac{1}{2\sigma^2}\left\| \mathbf{g} - \mathbf{s} \right\|^2_2 = \mathbf{g} \,.
\end{align}\)</span></p>
<p>We will get to know several suitable priors later on in this chapter but we want to stress one important point here:</p>
<p>Any algorithm that successfully denoises an image from normally distributed noise can be interpreted (and used) as a solution to the problem just described, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \argmin{\mathbf{s}}\, \frac{1}{2\sigma^2}\left\| \mathbf{g} - \mathbf{s} \right\|^2_2 + \Gamma (\mathbf{s}) \,.
\end{align}\)</span></p>
</section>
</section>
<section id="general-linear-inverse-problems">
<h2>General linear inverse problems<a class="headerlink" href="#general-linear-inverse-problems" title="Permalink to this headline">#</a></h2>
<p>For the general linear inverse problem, the vectorized image formation process is given by:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{b} = \mathbf{Ax} + \mathbf{n} \,,
\end{align}\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\mathbf{b} \in \mathbb{R} ^M\)</span> denotes the <span class="math notranslate nohighlight">\(M\)</span> observations or measurements which are the result of the matrix-vector multiplication of the sought latent image <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R} ^N\)</span> with the so-called <em>measurement matrix</em> <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R} ^{M \times N}\)</span> and the term <span class="math notranslate nohighlight">\(\mathbf{n} \in \mathbb{R} ^M\)</span> represents additive, signal-independent noise.</p>
<section id="bayesian-perspective-of-inverse-problems">
<h3>Bayesian perspective of inverse problems<a class="headerlink" href="#bayesian-perspective-of-inverse-problems" title="Permalink to this headline">#</a></h3>
<p>Interpret as random vectors:<br>
<span class="math notranslate nohighlight">\(\stochvec{x}\sim \mathcal{N}(\mathbf{x},0)\)</span>,<br>
<span class="math notranslate nohighlight">\(\stochvec{n}\sim \mathcal{N}(0,\sigma^2)\)</span>,<br>
<span class="math notranslate nohighlight">\( \stochvec{b}\sim \mathcal{N}((\mathbf{Ax}),\sigma^2)\)</span></p>
<p>For probability of observation <span class="math notranslate nohighlight">\( \mathbf{b}\)</span> it holds:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
    p( \mathbf{b}\vert \mathbf{x}, \sigma) \propto \exp \left( - \frac{\Vert \mathbf{b} - \mathbf{Ax} \Vert^2_2}{2\sigma^2} \right)
\end{align}
\)</span></p>
<p>According to Bayes’ rule:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
    \underbrace{p(\mathbf{x}\vert \mathbf{b},\sigma)}_{\mathrm{posterior}} = \frac{p( \mathbf{b}\vert \mathbf{x}, \sigma)\cdot p( \mathbf{x})}{p( \mathbf{b})} \propto \underbrace{p( \mathbf{b} \vert \mathbf{x}, \sigma)}_{\mathrm{image\ formation\ model}} \cdot \underbrace{p( \mathbf{x})}_\mathrm{prior}\,.
\end{align}
\)</span></p>
<p>Maximum-a-posteriori (MAP) solution:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
  \hat{x}_\mathrm{MAP} &amp;= \argmax{\mathbf{x}}\, p(\mathbf{x}\vert \mathbf{b},\sigma) \\
                         &amp;= \argmax{\mathbf{x}}\, \log p(\mathbf{x}\vert \mathbf{b},\sigma) \\
                         &amp;= \argmin{ \mathbf{x}}\, - \log p(\mathbf{x}\vert \mathbf{b},\sigma) \\
                         &amp;= \argmin{ \mathbf{x}}\, - \log p( \mathbf{b} \vert \mathbf{x}, \sigma) - \log p( \mathbf{x}) \\
                         \label{eq:map_solution}&amp;= \argmin{ \mathbf{x}}\, \underbrace{\frac{\Vert \mathbf{b} - \mathbf{Ax} \Vert^2_2}{2\sigma^2}}_{\mathrm{data\, fidelity\, term}} + \underbrace{\Psi(\mathbf{x})}_{ \mathrm{regularizer}}\,.                         
\end{align}
\)</span></p>
<p>The choice of image priors / regularizers depends on the imaging task, i.e., the nature of the images that are to be recovered. Examples are:</p>
<ul class="simple">
<li><p>Blurry imges <span class="math notranslate nohighlight">\(\rightarrow\)</span> promote smoothness <span class="math notranslate nohighlight">\(\Psi (\mathbf{x}) = \left\| \underbrace{\Delta}_{\text{Laplace operator}} \mathbf{x} \right\|_2 \)</span></p></li>
<li><p>Sparse images (e.g., stars) <span class="math notranslate nohighlight">\(\rightarrow\)</span> promote sparsity <span class="math notranslate nohighlight">\(\Psi (\mathbf{x}) = \left\| \mathbf{x} \right\|_1\)</span></p></li>
<li><p>Natural images <span class="math notranslate nohighlight">\(\rightarrow\)</span> promote sparse gradients <span class="math notranslate nohighlight">\(\mathrm{TV}(\mathbf{x})\)</span></p></li>
</ul>
</section>
<section id="total-variation">
<h3>Total Variation<a class="headerlink" href="#total-variation" title="Permalink to this headline">#</a></h3>
<p>The intuition behind total variation is that in natural images, regions of almost constant intensities are separated by sharp edges. Hence, the gradient of such images can be assumed to be sparse.</p>
<p>The gradient is calculated by means of convolutions with the finite difference operators in <span class="math notranslate nohighlight">\(x\)</span>- and <span class="math notranslate nohighlight">\(y\)</span>-direction:</p>
<ul class="simple">
<li><p>Finite difference in <span class="math notranslate nohighlight">\(x\)</span>-direction: <span class="math notranslate nohighlight">\(d_x * x = \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 1 \\ 0 &amp; 0 &amp; 0  \end{pmatrix} * x = \mathbf{D}_x \mathbf{x}\)</span></p></li>
<li><p>Finite difference in <span class="math notranslate nohighlight">\(y\)</span>-direction: <span class="math notranslate nohighlight">\(d_y * x = \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 \\ 0 &amp; 1 &amp; 0  \end{pmatrix} * x = \mathbf{D}_y \mathbf{x}\)</span></p></li>
</ul>
<ul class="simple">
<li><p>Anisotropic:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{TV}(\mathbf{x}) &amp;= \left\| \mathbf{D}_x \mathbf{x} \right\|_1 + \left\| \mathbf{D}_y \mathbf{x} \right\|_1 \\ 
  &amp;=  \sum\limits^N_{i=1}  \left| (\mathbf{D}_x \mathbf{x})_i \right| + \left| (\mathbf{D}_y \mathbf{x})_i \right| = \sum\limits^N_{i=1} \sqrt[]{(\mathbf{D}_x \mathbf{x})^2_i} + \sum\limits^N_{i=1} \sqrt[]{(\mathbf{D}_y \mathbf{x})^2_i} 
\end{align}\)</span></p>
<ul class="simple">
<li><p>Isotropic:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{TV}(\mathbf{x}) = \sum\limits^N_{i=1}\left\| \begin{bmatrix} (\mathbf{D}_x \mathbf{x})_i \\ (\mathbf{D}_y \mathbf{x})_i \end{bmatrix} \right\|_2 = \sum\limits^N_{i=1}  \sqrt[]{(\mathbf{D}_x \mathbf{x})^2_i + (\mathbf{D}_y \mathbf{x})^2_i}
\end{align}\,,\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\begin{bmatrix} \mathbf{a} \\ \mathbf{b} \end{bmatrix}\)</span> denoting a concatenation of the vectors <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> and <span class="math notranslate nohighlight">\((\mathbf{D_\mathrm{x} \mathbf{x}})_i\)</span> denoting the <span class="math notranslate nohighlight">\(i\)</span>-th element of the vector resulting from <span class="math notranslate nohighlight">\(\mathbf{D}_\mathrm{x} \mathbf{x}\)</span>.</p>
</section>
</section>
<section id="image-deconvolution">
<h2>Image deconvolution<a class="headerlink" href="#image-deconvolution" title="Permalink to this headline">#</a></h2>
<p>Image deconvolution deals with the problem of reconstructing an original image <span class="math notranslate nohighlight">\(s\)</span> after it has been affected by a linear shift-invariant image degradation and additive noise, which together forms the observed image <span class="math notranslate nohighlight">\(g\)</span>.</p>
<p>With the impulse response <span class="math notranslate nohighlight">\(h\)</span> of the image degradation, the observation can be modeled as</p>
<p><span class="math notranslate nohighlight">\(\begin{align} \label{eq:img_formation}
   g = s * h + n\,,
\end{align}\)</span></p>
<p>with the additive noise <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>The goal is to define a reconstruction filter <span class="math notranslate nohighlight">\(v\)</span> that, when applied to the observation <span class="math notranslate nohighlight">\(g\)</span>, yields a reconstruction <span class="math notranslate nohighlight">\(\hat{s}\)</span> matching the latent input <span class="math notranslate nohighlight">\(s\)</span> as closely as possible.</p>
<p>The following figure visualizes the signal model of image deconvolution:</p>
<img src="figures/6/signalmodel_reconstruction.svg" style="max-height:40vh"><p>Methods and approaches dealing with deconvolution can be divided into two groups:</p>
<ol class="simple">
<li><p><em>Blind</em> deconvolution: The kernel <span class="math notranslate nohighlight">\(h\)</span> is assumed to be unknown and also has to be recovered / estimated.</p></li>
<li><p><em>Non-blind</em> deconvolution: The kernel <span class="math notranslate nohighlight">\(h\)</span> is assumed to be known.</p></li>
</ol>
<p><br>Note that there is some research which focuses on estimating the kernel <span class="math notranslate nohighlight">\(h\)</span> and then employs non-blind deconvolution methods to perform the deconvolution.</p>
<p>According to the convolution theorem of the Fourier transform, equation <span class="math notranslate nohighlight">\(\eqref{eq:img_formation}\)</span> can be expressed as:
<span class="math notranslate nohighlight">\(\begin{align}\label{eq:img_formation_fourier}
    g = \mathcal{F}^{-1}\lbrace \mathcal{F} \lbrace h \rbrace \cdot \mathcal{F} \lbrace s \rbrace \rbrace + n
\end{align}\)</span></p>
<p><strong>Important note:</strong> Equations <span class="math notranslate nohighlight">\(\eqref{eq:img_formation}\)</span> and <span class="math notranslate nohighlight">\(\eqref{eq:img_formation_fourier}\)</span> only result in the same numbers, if the convolution is performed with ciruclar boundary conditions, i.e., when the convolution kernel wraps around the image borders.</p>
<section id="duality-between-signal-processing-perspective-and-algebraic-perspective">
<h3>Duality between signal processing perspective and algebraic perspective<a class="headerlink" href="#duality-between-signal-processing-perspective-and-algebraic-perspective" title="Permalink to this headline">#</a></h3>
<p>Since the convolution is a linear operator, it can also be expressed in terms of a matrix vector multiplication:
<span class="math notranslate nohighlight">\(\begin{align}\label{eq:duality}
    g = h*s \Leftrightarrow \mathbf{g} = \mathbf{H}\mathbf{s}\,,
\end{align}\)</span>
with a square circulant Toeplitz matrix <span class="math notranslate nohighlight">\(\mathbf{H}\in \mathbb{R}^{N\times N}\)</span> implementing the convolution and <span class="math notranslate nohighlight">\(\mathbf{g,s} \in \mathbb{R}^N\)</span> representing the vectorized forms of the corresponding images <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(s\)</span>.</p>
</section>
</section>
<section id="inverse-filter-for-deconvolution">
<h2>Inverse filter for deconvolution<a class="headerlink" href="#inverse-filter-for-deconvolution" title="Permalink to this headline">#</a></h2>
<p>The inverse filter represents the straightforward approach of solving equation <span class="math notranslate nohighlight">\(\eqref{eq:img_formation_fourier}\)</span> for <span class="math notranslate nohighlight">\(s\)</span> while neglecting the noise <span class="math notranslate nohighlight">\(n\)</span>:
<span class="math notranslate nohighlight">\(\begin{align}\label{eq:inv_filter}
        \hat{s}_{\mathrm{inv}}=\Fi\left\lbrace \frac{\F\lbrace g \rbrace}{\F\lbrace h \rbrace } \right\rbrace \,.
\end{align}\)</span></p>
<p>Properties of the inverse filter:</p>
<ul class="simple">
<li><p>computationally efficient,</p></li>
<li><p>problematic for small values of <span class="math notranslate nohighlight">\(\F \lbrace h \rbrace\)</span>, (amplifies noise).</p></li>
</ul>
<p>Unfortunately, the second point is true for most practically relevant point spread functions.</p>
<section id="example-inverse-filter-reconstruction-results-for-increasing-noise-levels">
<h3>Example inverse filter reconstruction results for increasing noise levels<a class="headerlink" href="#example-inverse-filter-reconstruction-results-for-increasing-noise-levels" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">showFig</span><span class="p">(</span><span class="s1">&#39;figures/6/inv_filter_res_&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;.svg&#39;</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">i</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="p">(</span><span class="n">min_i</span><span class="o">:=</span><span class="mi">1</span><span class="p">),</span><span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span><span class="o">:=</span><span class="mi">6</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span> <span class="k">if</span> <span class="n">book</span> <span class="k">else</span> <span class="n">min_i</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "abc8e1ea1a2f45f7b8a759170da0ac76"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(i)&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="wiener-filter-for-deconvolution">
<h2>Wiener filter for deconvolution<a class="headerlink" href="#wiener-filter-for-deconvolution" title="Permalink to this headline">#</a></h2>
<p>The Wiener filter has been proposed by Norbert Wiener in 1949 and minimizes the mean squared error between the original image <span class="math notranslate nohighlight">\(s\)</span> and the reconstruction <span class="math notranslate nohighlight">\(\hat{s}\)</span>.</p>
<p>The filter is obtained by assuming the involved images to be weakly stationary stochastic processes so that they can be described via their power spectral densities (not covered here).</p>
<p>In the Fourier-domain, the Wiener filter is given by</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   V(\mathbf{f}) = \frac{H(\mathbf{f})^*}{\left| H(\mathbf{f}) \right|^2 + \underbrace{\frac{S_{nn}(\mathbf{f})}{S_{ss}(\mathbf{f})}}_{=:SNR^{-1}(\mathbf{f})} } \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(H(\mathbf{f})^*\)</span> denoting the complex conjugate of <span class="math notranslate nohighlight">\(H(\mathbf{f})\)</span> and <span class="math notranslate nohighlight">\(S_{nn}(\mathbf{f}), S_{ss}(\mathbf{f})\)</span> denoting the power spectral densities of the noise <span class="math notranslate nohighlight">\(n\)</span> and the original image <span class="math notranslate nohighlight">\(s\)</span>. The quotient <span class="math notranslate nohighlight">\(\frac{S_{ss}(\mathbf{f})}{S_{nn}(\mathbf{f})}\)</span> represents the signal-to-noise ration <span class="math notranslate nohighlight">\(SNR(\mathbf{f})\)</span> between <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>For frequencies with high signal-to-noise ratios, the Wiener filter resembles the inverse filter and for low signal-to-noise ratios, it pulls yields values close to zero in order not to amplify any noise.</p>
<p>One of the main practical problems of the Wiener filter is the dependence on the signal-to-noise ratio <span class="math notranslate nohighlight">\(SNR(\mathbf{f})\)</span> which can not be determined exactly as it involves the power spectral density of the unknown, original image <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>A common heuristic for providing the signal-to-noise ratio is</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   SNR_\mathrm{{heur}} (\mathbf{f}) = \frac{1}{\left\| \mathbf{f} \right\|_2 } \,,
\end{align}\)</span></p>
<p>i.e., to steadily decrease the filtering for higher spatial frequencies as noise is typically dominated by high spatial frequencies.</p>
<p>Later we will see another method for estimating the signal-to-noise ratio that takes the actual processed image <span class="math notranslate nohighlight">\(g\)</span> into account.</p>
<section id="example-wiener-filter-reconstruction-results-for-increasing-noise-levels-with-snr-heuristics">
<h3>Example Wiener filter reconstruction results for increasing noise levels with SNR-heuristics<a class="headerlink" href="#example-wiener-filter-reconstruction-results-for-increasing-noise-levels-with-snr-heuristics" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">showFig</span><span class="p">(</span><span class="s1">&#39;figures/6/wiener_filter_res_&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;.svg&#39;</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">i</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="p">(</span><span class="n">min_i</span><span class="o">:=</span><span class="mi">1</span><span class="p">),</span><span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span><span class="o">:=</span><span class="mi">6</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span> <span class="k">if</span> <span class="n">book</span> <span class="k">else</span> <span class="n">min_i</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "9a61fa7dace041269b9ff8dbe3c7c544"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(i)&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="richardson-lucy-deconvolution">
<h2>Richardson-Lucy deconvolution<a class="headerlink" href="#richardson-lucy-deconvolution" title="Permalink to this headline">#</a></h2>
<p>The Richardson-Lucy deconvolution algorithm (RL-algorithm) has been simultaneously and independently proposed by William Richardson and Leon Lucy in the 1970s.</p>
<p>It is based on the assumption that the noise affecting digitally acquired images is dominated by the so-called <em>shot noise</em> caused by the stochastic nature of the number of arriving photons.</p>
<p>We again consider the image formation process</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   g = s * h + n\,,
\end{align}\)</span></p>
<p>with the observed image <span class="math notranslate nohighlight">\(g\)</span>, the sought original image <span class="math notranslate nohighlight">\(s\)</span>, the convolution kernel <span class="math notranslate nohighlight">\(h\)</span> and the additive noise <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>The probability <span class="math notranslate nohighlight">\(p(g)\)</span> that a single pixel collects <span class="math notranslate nohighlight">\(g\)</span> photons during one exposure period can be modelled by means of a Poisson distribution:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   p(g) = \mathrm{e}^{-\lambda} \cdot \frac{\lambda^g}{g!} \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\lambda\)</span> denoting the expected number of photons collected during one exposure.</p>
<p>In order to obtain a noise-free image, one would need to obtain <span class="math notranslate nohighlight">\(\lambda\)</span> by means of the measured <span class="math notranslate nohighlight">\(g\)</span> photons (precisely, photoelectrons).</p>
<p>Since the joint probability of two independent events is the product of their individual probabilities, the joint probability of recording the intensities <span class="math notranslate nohighlight">\(g\)</span> of a whole image can expressed via:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   P(g) = \prod_{(x,y)\in \Omega_g} \mathrm{e}^{-\Lambda_{x,y}} \cdot \frac{\Lambda_{x,y}^{b_{x,y}}}{g_{x,y}!} \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\Omega_g\)</span> denoting the spatial support of the image <span class="math notranslate nohighlight">\(g\)</span>, <span class="math notranslate nohighlight">\(\Lambda_{x,y}\)</span> denoting the value of the sought noise-free image <span class="math notranslate nohighlight">\(\Lambda\)</span> at position <span class="math notranslate nohighlight">\((x,y)\)</span> and <span class="math notranslate nohighlight">\(g_{x,y}\)</span> denoting the pixel value of the image <span class="math notranslate nohighlight">\(g\)</span> at position <span class="math notranslate nohighlight">\((x,y)\)</span>. All operations are considered element-wise.</p>
<p>To improve readability, we will omit the pixel index <span class="math notranslate nohighlight">\((x,y)\)</span> from now on.</p>
<p>To obtain the noise-free image, we have to guess the hidden expected values <span class="math notranslate nohighlight">\(\hat{\Lambda}\)</span> that match the observed image <span class="math notranslate nohighlight">\(g\)</span> as closely as possible.</p>
<p>We can achieve this by finding a <span class="math notranslate nohighlight">\(\hat{\Lambda}\)</span> that maximizes <span class="math notranslate nohighlight">\(P(g)\)</span>, or, equivalently, that maximizes <span class="math notranslate nohighlight">\(\log P(g)\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \log P(g) &amp;= \log \left( \prod \mathrm{e}^{-\Lambda} \cdot \frac{\Lambda^g}{g!} \right) \\
  &amp;= \sum \log \left(  \mathrm{e}^{-\Lambda} \cdot \frac{\Lambda^g}{g!} \right) \\
  &amp;= \sum \left( \log e^{-\Lambda} + g\log \Lambda - \log g! \right) \\
  &amp;= -\sum \left( \Lambda-g\log \Lambda + \log g!  \right) \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\log\)</span> denoting the natural logarithm.</p>
<p>The last term in the summation, i.e., <span class="math notranslate nohighlight">\(\log g!\)</span>, can be ignored since it does not depend on <span class="math notranslate nohighlight">\(\Lambda\)</span>.</p>
<p>The noise-free image <span class="math notranslate nohighlight">\(\Lambda\)</span> is the result of</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \Lambda = s * h \,,
\end{align}\)</span></p>
<p>i.e., the convolution of the noise-free, original image <span class="math notranslate nohighlight">\(s\)</span> with the convolution kernel <span class="math notranslate nohighlight">\(h\)</span>.</p>
<p>And the observed image <span class="math notranslate nohighlight">\(g\)</span> is the result Of</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   g = s * h + n \,,
\end{align}\)</span></p>
<p>i.e., <span class="math notranslate nohighlight">\(\Lambda\)</span> with additive noise <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>These two expressions can be inserted into the equation of <span class="math notranslate nohighlight">\(\log P(g)\)</span> in order to get to our optimization goal of finding an <span class="math notranslate nohighlight">\(\hat{s}\)</span> that maximizes <span class="math notranslate nohighlight">\(\log P(g)\)</span>, i.e., minimizes <span class="math notranslate nohighlight">\(-\log P(g)\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \hat{s} = \argmin{s}\, \underbrace{ \sum \left( s * h-g\log (s * h)  \right)}_{=:J(s)} \,,
\end{align}\)</span></p>
<p>with the optimization functional <span class="math notranslate nohighlight">\(J(s)\)</span>.</p>
<p>To perform the optimization, we can employ gradient descent on <span class="math notranslate nohighlight">\(J(s)\)</span>. The gradient <span class="math notranslate nohighlight">\(\nabla J=\frac{\partial J(s)}{\partial s}\)</span> of <span class="math notranslate nohighlight">\(J(s)\)</span> w.r.t. <span class="math notranslate nohighlight">\(s\)</span> is given by:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \nabla J(s) = \left( 1 - \frac{g}{s*h} \right) * h\transp \,,
\end{align}\)</span></p>
<p>with element-wise multiplication and division.</p>
<p>For an initial guess of <span class="math notranslate nohighlight">\(\hat{s}_0 := g\)</span>, the gradient descent iteration for the Richardson-Lucy algorithm is</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \hat{s}_{i+1} = \hat{s}_i - \eta \nabla J(s_i) = \hat{s}_i - \eta \left( 1 - \frac{g}{s_i*h} \right) * h\transp \,.
\end{align}\)</span></p>
<section id="multiplicative-version-of-the-richardson-lucy-algorithm">
<h3>Multiplicative version of the Richardson-Lucy algorithm<a class="headerlink" href="#multiplicative-version-of-the-richardson-lucy-algorithm" title="Permalink to this headline">#</a></h3>
<p>The most implemented version of the RL-algorithm is the so-called <em>multiplicative RL-algorithm</em>.</p>
<p>It relies on the convolution kernel <span class="math notranslate nohighlight">\(h\)</span> being normalized, i.e., <span class="math notranslate nohighlight">\(\sum_{(i,j)} h_{i,j} = 1\)</span>.</p>
<p>This also implies that <span class="math notranslate nohighlight">\(1*h\transp=1\)</span>.</p>
<p>The multiplicative RL-algorithm is derived by equating <span class="math notranslate nohighlight">\(J(s)\)</span> to zero. This results in:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   1 = \frac{g}{s*h}*h\transp \,.
\end{align}\)</span></p>
<p>Since <span class="math notranslate nohighlight">\(J(s)\)</span> is a convex function, it decreases with every step of gradient descent until it does not change anymore, i.e., until it holds</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \frac{\hat{s}_{i+1}}{\hat{s}_i} = 1 \,.
\end{align}\)</span></p>
<p>We use this expression to substitute <span class="math notranslate nohighlight">\(1\)</span> in the equation before and arrive at the sought multiplicative formulation of the RL-algorithm:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \frac{\hat{s}_{i+1}}{\hat{s}_i} &amp;= \frac{g}{s*h}*h\transp \quad \Leftrightarrow \\
  \hat{s}_{i+1} &amp;= \hat{s}_i \frac{g}{\hat{s}_i*h}*h\transp \,.
\end{align}\)</span></p>
<section id="comments-on-the-richardson-lucy-algorithm">
<h4>Comments on the Richardson-Lucy algorithm<a class="headerlink" href="#comments-on-the-richardson-lucy-algorithm" title="Permalink to this headline">#</a></h4>
<p>The RL-algorithm is implemented in many open source or commercial image processing libraries.</p>
<p>The main problem of the RL-algorithm is that it starts to amplify noise after its (usually quick) convergence. Hence, the intermediate results have to be continuously inspected or some sort of regularization has to be incorporated into the optimization functional <span class="math notranslate nohighlight">\(J\)</span>.</p>
</section>
</section>
</section>
<section id="half-quadratic-splitting-hqs-method">
<h2>Half-quadratic splitting (HQS) method<a class="headerlink" href="#half-quadratic-splitting-hqs-method" title="Permalink to this headline">#</a></h2>
<p>This section introduces a flexible, powerful and intuitive iterative approach, the half-quadratic splitting (HQS) method, for solving regularized inverse problems formulated like \eqref{eq:map_solution}.</p>
<p>We start with some general considerations and then apply HQS to the inverse problem of deconvolution.</p>
<p>We assume the following image formation model:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathbf{b} = \mathbf{Ax} + \mathbf{\eta},
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\mathbf{x}\in \mathbb{R}^{N}\)</span> denoting the unknown vector, <span class="math notranslate nohighlight">\(\mathbf{b}\in \mathbb{R}^{M}\)</span> representing the observations, the additive noise <span class="math notranslate nohighlight">\(\mathbf{\eta}\in \mathbb{R}^{M}\)</span> and the matrix <span class="math notranslate nohighlight">\(\mathbf{A}\in \mathbb{R}^{M\times N}\)</span> encoding the linear image formation model.</p>
<p>Equation \eqref{eq:map_solution} leads us to the general formulation of regularized inverse problems in the field of computational imaging:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align}\label{eq:general_inverse_problem} 
  \hat{\mathbf{x}} = \argmin{\mathbf{x}} \, \underbrace{\frac{1}{2} \left\| \mathbf{Ax-b} \right\|^2_2}_{\text{data fidelity term}} + \underbrace{\lambda \Psi (\mathbf{x}) }_{\text{regularizer}}\,.
\end{align}
\)</span></p>
<p>The data fidelity term ensures that the sought solution <span class="math notranslate nohighlight">\(\mathbf{\hat{x}}\)</span> matches the observed data <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> when fed through the image formation process (modelled by <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>). The regularization operator <span class="math notranslate nohighlight">\(\Psi : \mathbb{R}^{N} \rightarrow \mathbb{R}^M\)</span> models prior knowledge about the unknown original data <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. The scalar parameter <span class="math notranslate nohighlight">\(\lambda \)</span> balances between the data fidelity term and the regularization term and hence <span class="math notranslate nohighlight">\(\lambda \in [ 0,1 ]\)</span>.</p>
<p>Trying to directly solve \eqref{eq:general_inverse_problem}, e.g., via gradient descent, often does not work well. Reasons are poor convergence or difficulties in finding an efficient way to calculate the gradient. Even worse, whenever we change the regularizer, we will have to re-write the optimization program again.</p>
<p>Hence, rewrite \eqref{eq:general_inverse_problem} to:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} \label{eq:hqs_1}
  \argmin{\mathbf{x}}\quad &amp;\underbrace{\frac{1}{2}\left\| \mathbf{Ax-b} \right\|^2_2 }_{=:f(\mathbf{x})} + \underbrace{\lambda \Psi (\mathbf{z})}_{=:g(\mathbf{z})} \\
  \text{subject to}\quad &amp;\mathbf{Dx-z} = \mathbf{0} \,.
\end{align}
\)</span></p>
<p>We introduced a so-called <em>slack variable</em> <span class="math notranslate nohighlight">\(\mathbf{z}\in \mathbb{R}^O\)</span> which allows us to separate the data fidelity term and the regularization term so that they do not depend on the same variable anymore. Obviously, <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> are still linked by the constraint <span class="math notranslate nohighlight">\(\mathbf{Dx-z=0}\)</span>.</p>
<p>For now, we assume <span class="math notranslate nohighlight">\(\mathbf{D}\in \mathbb{R}^{O\times N}\)</span> to represent the identity matrix (i.e., it does not introduce any changes and can be ignored for now) - it will come back into play later on.</p>
<p>We now include the constraint of \eqref{eq:hqs_1} directly in the main optimization objective term via a penalty term:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align}\label{eq:hqs_2}
 L_\rho (\mathbf{x}, \mathbf{z}) = f(\mathbf{x}) + g(\mathbf{z}) + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\|^2_2\,, \qquad \text{with }\rho &gt; 0\,.
\end{align}
\)</span></p>
<p>Intuitively, setting <span class="math notranslate nohighlight">\(\rho\)</span> to a large value leads to the same results for minimizing \eqref{eq:hqs_1} and \eqref{eq:hqs_2}. The benefit of this reformulation is that we can perform gradient descent for <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> in an alternating fashion.</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
   &amp;\mathbf{x} \leftarrow \mathrm{prox}_{f,\rho} (\mathbf{z}) = \argmin{\mathbf{x}}\, L_\rho (\mathbf{x}, \mathbf{z}) = \argmin{\mathbf{x}}\, f(\mathbf{x}) + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\|^2_2\,, \\
   &amp;\mathbf{z} \leftarrow \mathrm{prox}_{g,\rho} (\mathbf{Dx}) = \argmin{\mathbf{z}}\, L_\rho (\mathbf{x}, \mathbf{z}) = \argmin{\mathbf{z}}\, g(\mathbf{z}) + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\|^2_2\,.
\end{align}
\)</span></p>
<p>Again, the important benefit of this formulation is that we can update <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> separately. We will see that this approach allows us to easily experiment with different regularizers (this is sometimes also referred to as a <em>plug-and-play</em> formulation).</p>
<section id="excursion-on-proximal-operators">
<h3>Excursion on proximal operators<a class="headerlink" href="#excursion-on-proximal-operators" title="Permalink to this headline">#</a></h3>
<p>So-called <em>proximal operators</em> are used in <em>proximal algorithms</em> to solve</p>
<ul class="simple">
<li><p>large-scale,</p></li>
<li><p>non-smooth and</p></li>
<li><p>constrained
convex optimization problems.</p></li>
</ul>
<p>Similar to calculating the gradient of the target function <span class="math notranslate nohighlight">\(f\)</span> in gradient descent, one evaluates the corresponding proximal operator to take one step into the direction of the sought minimum.</p>
<section id="definition-of-a-proximal-operator">
<h4>Definition of a proximal operator<a class="headerlink" href="#definition-of-a-proximal-operator" title="Permalink to this headline">#</a></h4>
<p>Assume <span class="math notranslate nohighlight">\(f:\mathbb{R} ^n \rightarrow  \mathbb{R} \cup \left\{ +\infty \right\} \)</span> to be a closed proper convex function, i.e., with its <em>epigraph</em></p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{epi}_t f := \left\{ (x,t) \in \mathbb{R} ^n \times \mathbb{R} \vert f(x) \leq  t  \right\}
\end{align}\)</span></p>
<p>being a nonempty closed convex set.</p>
<p>The proximal operator <span class="math notranslate nohighlight">\(\mathrm{prox}_f (v):\mathbb{R} ^n \rightarrow \mathbb{R}^n\)</span> of <span class="math notranslate nohighlight">\(f\)</span> is defined as</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{prox}_f (v) = \argmin{x}\, \left( f(x) + \frac{1}{2} \left\| x-v \right\|^2_2  \right)  \,.
\end{align}\)</span></p>
<p>The minimized term on the right-hand side is strongly convex and not infinite everywhere, so it has a unique solution for every <span class="math notranslate nohighlight">\(v\in \mathbb{R} ^n\)</span>.</p>
<p>Often the proximal operator for the scaled function <span class="math notranslate nohighlight">\(\lambda f\)</span>, with <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span>, is of interested, which we denote as:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{f,\lambda} (v) = \argmin{x}\, \left( f(x) + \frac{1}{2} \lambda \left\| x-v \right\|^2_2  \right)  \,.   
\end{align}\)</span></p>
</section>
<section id="interpretation-of-proximal-operators">
<h4>Interpretation of proximal operators<a class="headerlink" href="#interpretation-of-proximal-operators" title="Permalink to this headline">#</a></h4>
<p>Intuitively, a proximal operator <span class="math notranslate nohighlight">\(\mathrm{prox}_f (v)\)</span> yields a point that is a compromise between minimizing <span class="math notranslate nohighlight">\(f\)</span> and being  near to <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p>In the scaled version <span class="math notranslate nohighlight">\(\mathrm{prox}_{f,\lambda} (v)\)</span>, <span class="math notranslate nohighlight">\(\lambda\)</span> acts like a relative weight between the two terms.</p>
<p>The effect of a proximal operator can be visualized as follows:</p>
<img src="figures/6/illustration_proximal_operator.svg" style="max-height:40vh"><p>Points <span class="math notranslate nohighlight">\(v\)</span> inside the domain of <span class="math notranslate nohighlight">\(f\)</span> are moved by the proximal operator so that they stay in the domain and get closer to the minimum of <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Points <span class="math notranslate nohighlight">\(v\)</span> outside the domain of <span class="math notranslate nohighlight">\(f\)</span> are moved onto the boundary of <span class="math notranslate nohighlight">\(f\)</span> and in the direction of the minimum of <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Proximal operators can also be interpreted as a kind of gradient descent step in the sense that</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{prox}_{f, \lambda}(v) \approx v - \lambda \nabla f(v) \,,
\end{align}\)</span></p>
<p>when <span class="math notranslate nohighlight">\(\lambda\)</span> is small and <span class="math notranslate nohighlight">\(f\)</span> is differentiable.</p>
</section>
</section>
<section id="hqs-for-deconvolution">
<h3>HQS for deconvolution<a class="headerlink" href="#hqs-for-deconvolution" title="Permalink to this headline">#</a></h3>
<p>We now again consider the inverse problem of deconvolution with circual boundary conditions. Here, the matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is the square circulant Toeplitz matrix <span class="math notranslate nohighlight">\(\mathbf{C} \in \mathbb{R}^{N\times N}\)</span> representing a 2D-convolution of the input image <span class="math notranslate nohighlight">\(x\)</span> with the convolution kernel <span class="math notranslate nohighlight">\(c\)</span>.</p>
<p>Revise the duality between the signal processing formulation and the algebraic formulation:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
   c*x = \Fi \left\{ \F \left\{ c \right\} \cdot \F \left\{ x \right\}  \right\} &amp;\Leftrightarrow \mathbf{Cx} \,, \\
   \Fi \left\{ \F \left\{ c \right\}^* \cdot \F \left\{ x \right\}   \right\} &amp;\Leftrightarrow \mathbf{C}\transp \mathbf{x}\,, \\
   \Fi \left\{ \frac{\F \left\{ b \right\} }{\F \left\{ c \right\} } \right\} &amp;\Leftrightarrow \mathbf{C}^{-1} \mathbf{b}\,.
\end{align}
\)</span></p>
<section id="hqs-with-total-variation-and-denoising-regularizers">
<h4>HQS with total variation and denoising regularizers<a class="headerlink" href="#hqs-with-total-variation-and-denoising-regularizers" title="Permalink to this headline">#</a></h4>
<p>The initial formulation \eqref{eq:hqs_1} of HQS depends on which regularizer we employ.</p>
<p>For total variation this is:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
  \argmin{\mathbf{x}}\quad &amp;\underbrace{\frac{1}{2}\left\| \mathbf{Cx-b} \right\|^2_2 }_{=:f(\mathbf{x})} + \underbrace{\lambda \left\| \mathbf{z} \right\|_1 }_{=:g(\mathbf{z})} \\
  \text{subject to}\quad &amp;\mathbf{Dx-z} = \mathbf{0} \,,
\end{align}
\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\mathbf{D} = \left[ \mathbf{D}\transp_x \mathbf{D}\transp_y \right]\transp \in \mathbb{R}^{2N \times N}\)</span> representing the finite difference operator for calculating the gradients of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> in <span class="math notranslate nohighlight">\(x\)</span>- and <span class="math notranslate nohighlight">\(y\)</span>-direction.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The vector <span class="math notranslate nohighlight">\(\mathbf{z}\in \mathbb{R}^{2N}\)</span> has to be twice as large as <span class="math notranslate nohighlight">\(\mathbf{x}\in \mathbb{R}^{N} \)</span> in order to store the two gradient values in <span class="math notranslate nohighlight">\(x\)</span>- and <span class="math notranslate nohighlight">\(y\)</span>-direction for every input pixel.</p>
</div>
<p>In the more general case, we use a regularizer <span class="math notranslate nohighlight">\(\Psi \)</span> projecting an image onto the set of feasible natural images:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
  \argmin{\mathbf{x}}\quad &amp;\underbrace{\frac{1}{2}\left\| \mathbf{Cx-b} \right\|^2_2 }_{=:f(\mathbf{x})} + \underbrace{\lambda  \Psi (\mathbf{z})}_{=:g(\mathbf{z})} \\
  \text{subject to}\quad &amp;\mathbf{x-z} = \mathbf{0} \,.
\end{align}
\)</span></p>
<p>Here the matrix <span class="math notranslate nohighlight">\(D\)</span> represents the identity matrix which is why it can be omitted.</p>
<section id="efficient-implementation-of-x-update">
<h5>Efficient implementation of <span class="math notranslate nohighlight">\(x\)</span>-update<a class="headerlink" href="#efficient-implementation-of-x-update" title="Permalink to this headline">#</a></h5>
<p>For obtaining the <span class="math notranslate nohighlight">\(x\)</span>-update, we have to derive the proximal operator <span class="math notranslate nohighlight">\(\mathrm{prox}_{f,\rho}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
  \mathrm{prox}_{f,\rho} (\mathbf{z}) = \argmin{\mathbf{x}}\, f(\mathbf{x}) + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\|^2_2 = \argmin{\mathbf{x}}\, \frac{1}{2} \left\| \mathbf{Cx-b} \right\|^2_2 + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\|^2_2 \,.
\end{align}
\)</span></p>
<p>Hence, we have to derive the gradient of that equation with respect to <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<p>We iteratively expand that equation as follows:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
  &amp;\frac{1}{2} \left\| \mathbf{Cx-b} \right\|^2_2 + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\|^2_2 \\
  =&amp;\frac{1}{2} (\mathbf{Cx-b})\transp (\mathbf{Cx-b}) + \frac{\rho}{2} (\mathbf{Dx-z})\transp (\mathbf{Dx-z}) \\
  =&amp;\frac{1}{2} (\mathbf{x}\transp \mathbf{C}\transp \mathbf{Cx} - 2\mathbf{x}\transp \mathbf{C}\transp \mathbf{b} + \mathbf{b}\transp \mathbf{b}) + \frac{\rho}{2} (\mathbf{x}\transp \mathbf{D}\transp \mathbf{D} \mathbf{x} - 2 \mathbf{x}\transp \mathbf{D}\transp \mathbf{z} + \mathbf{z}\transp\mathbf{z}) \,.
\end{align}
\)</span></p>
<p>The sought gradient is</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
   \mathbf{C}\transp \mathbf{Cx} - \mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{Dx} - \rho \mathbf{D}\transp \mathbf{z} \,.
\end{align}
\)</span></p>
<p>This expression can now be equated to zero and solved for <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<p>The single steps are:</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
  \mathbf{C}\transp \mathbf{Cx} - \mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{Dx} - \rho \mathbf{D}\transp \mathbf{z}\quad &amp;\overset{!}{=} \quad \mathbf{0} \\
  \mathbf{C}\transp \mathbf{Cx} + \rho \mathbf{D}\transp \mathbf{Dx}
  &amp;\overset{!}{=} \quad \mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{z} \\
  (\mathbf{C}\transp \mathbf{C} + \rho \mathbf{D}\transp \mathbf{D})\mathbf{x}
  &amp;\overset{!}{=} \quad \mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{z} \\
  \mathbf{x} &amp;\overset{!}{=} (\mathbf{C}\transp \mathbf{C} + \rho \mathbf{D}\transp \mathbf{D})^{-1}(\mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{z}) \,.
\end{align}
\)</span></p>
<p>This yields a first formulation for the sought proximal operator:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}\label{eq:hqs_tv_1} 
  \mathrm{prox}_{f,\rho} (\mathbf{z}) = (\mathbf{C}\transp \mathbf{C} + \rho \mathbf{D}\transp \mathbf{D})^{-1}(\mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{z}) \,.
\end{align}\)</span></p>
</section>
<section id="special-case-of-total-variation-regularizer">
<h5>Special case of total variation regularizer<a class="headerlink" href="#special-case-of-total-variation-regularizer" title="Permalink to this headline">#</a></h5>
<p>For the TV regularizer, the matrix <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> represents the finite difference operator.  The matrix-vector multiplications involved in the proximal operator, i.e., <span class="math notranslate nohighlight">\(\mathbf{Cx}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Dx} = \left[ \mathbf{D}\transp_x \mathbf{D}\transp_y  \right]\transp \mathbf{x}\)</span> (and also their adjoint correspondencies <span class="math notranslate nohighlight">\(\mathbf{C}\transp \mathbf{b}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{D}\transp \mathbf{z} = \left[ \mathbf{D}\transp_x \mathbf{D}\transp_y  \right] \mathbf{z}   \)</span> ) all encode 2D-convolutions with circular boundary conditions.</p>
<p>Exploiting the duality of the signal-processing perspective and the algebraic perspective yields the following reforumlations of the denominator, respectively, of the nominator of \eqref{eq:hqs_tv_1}:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  (\mathbf{C}\transp \mathbf{C} + \rho \mathbf{D}\transp \mathbf{D}) &amp;\Leftrightarrow \Fi \left\{ \F \left\{ c \right\}^* \cdot \F \left\{ c \right\} + \rho \left( \F \left\{ d_x \right\}^* \cdot \F \left\{ d_x \right\} + \F \left\{ d_y \right\}^* \cdot \F \left\{  d_y \right\}     \right)   \right\} \, , \\
  (\mathbf{C}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{z}) &amp;\Leftrightarrow \Fi \left\{ \F \left\{ c \right\}^* \cdot \F \left\{ b \right\} + \rho \left( \F \left\{ d_x \right\}^* \cdot \F \left\{ z \right\} + \F \left\{ d_y \right\}^* \cdot \F \left\{  z \right\}  	  \right)   \right\} \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\((\cdot)^*\)</span> denoting the element-wise complex conjugate.</p>
<p>Combining both terms in the original fraction yields the sought proximal operator:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{\left\| \cdot \right\|_2 ,\rho} (\mathbf{z}) = \Fi \left\{  \frac{\F \left\{ c \right\}^* \cdot \F \left\{ b \right\} + \rho \left( \F \left\{ d_x \right\}^* \cdot \F \left\{ z \right\} + \F \left\{ d_y \right\}^* \cdot \F \left\{  z \right\}  	  \right)}{\F \left\{ c \right\}^* \cdot \F \left\{ c \right\} + \rho \left( \F \left\{ d_x \right\}^* \cdot \F \left\{ d_x \right\} + \F \left\{ d_y \right\}^* \cdot \F \left\{  d_y \right\}     \right)} \right\} \,.
\end{align}\)</span></p>
<p>As for the inverse filer introduced before, this proximal operator is also unstable with respect to noise and zeros in the involved Fourier transforms. However, the integration into the HQS iterations will mitigate these effects so that the resulting estimate <span class="math notranslate nohighlight">\(\mathbf{\hat{x}}\)</span> will not be affected.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All terms of the proximal operator that do not depend on <span class="math notranslate nohighlight">\(z\)</span> only have to be computed once and can then be reused.</p>
</div>
</section>
<section id="general-regularizer">
<h5>General regularizer<a class="headerlink" href="#general-regularizer" title="Permalink to this headline">#</a></h5>
<p>For a general regularizer, we assume <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> to be the identity matrix so that it can be ignored. The proximal operator can then be written as:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{\left\| \cdot \right\|_2 ,\rho} (\mathbf{z}) = \Fi \left\{ \frac{\F \left\{ c \right\}^* \cdot \F \left\{ b \right\} + \rho \F \left\{ z \right\}  }{\F \left\{ c \right\}^* \cdot \F \left\{ c \right\} + \rho}  \right\} \,.
\end{align}\)</span></p>
</section>
<section id="efficient-implementation-of-z-update-for-anisotropic-tv-regularizer">
<h5>Efficient implementation of <span class="math notranslate nohighlight">\(z\)</span>-update for anisotropic TV regularizer<a class="headerlink" href="#efficient-implementation-of-z-update-for-anisotropic-tv-regularizer" title="Permalink to this headline">#</a></h5>
<p>For the <span class="math notranslate nohighlight">\(z\)</span>-update, we need to find a solution for the proximal operator</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{prox}_{\left\| \cdot \right\|_1, \rho } (\mathbf{Dx}) = \argmin{\mathbf{z}}\, \lambda \left\| \mathbf{z} \right\|_1 + \frac{\rho}{2}\left\| \mathbf{Dx-z} \right\|^2_2 \,.  
\end{align}\)</span></p>
<p>To simplify the writing, we substitute <span class="math notranslate nohighlight">\(\mathbf{v} = \mathbf{Dx}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{\left\| \cdot \right\|_1, \rho } (\mathbf{v}) = \argmin{\mathbf{z}}\, \lambda \left\| \mathbf{z} \right\|_1 + \frac{\rho}{2}\left\| \mathbf{v-z} \right\|^2_2 \,.  
\end{align}\)</span></p>
<p>We now have to calculate the gradient of that expression with respect to <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>. To easily follow the derivation, we will work on a single element of the gradient, i.e., we consider the scalar function</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   h(z) = \frac{\rho}{2}(v-z)^2 + \lambda \vert z \vert \,.
\end{align}\)</span></p>
<p>In order to calculate the gradient <span class="math notranslate nohighlight">\(h'(z)\)</span> of <span class="math notranslate nohighlight">\(h(z)\)</span>, we can work on the two terms of the addition separately. The derivative of the first term <span class="math notranslate nohighlight">\(\frac{\rho}{2}(v-z)^2\)</span> is</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \frac{\mathrm{d}}{\mathrm{d}z}\,\, \frac{\rho}{2}(v-z)^2 = \rho (-v + z) \,.
\end{align}\)</span></p>
<p>Unfortunately, the absolute value function <span class="math notranslate nohighlight">\(\vert \cdot \vert\)</span> (i.e., the 1-norm <span class="math notranslate nohighlight">\(\left\| \cdot \right\|_1\)</span>) is not differentiable and we have to take a detour to solve that problem.</p>
<p>For convex functions there is the concept of subdifferentials and subgradients which can be employed to approximate the gradient of convex functions at positions where they are not differentiable.</p>
<p>Consider a convex function <span class="math notranslate nohighlight">\(f:\mathcal{S} \rightarrow \mathbb{R}\)</span> defined on the open interval <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. According to Taylor’s theorem, the linear approximation of such a function <span class="math notranslate nohighlight">\(f\)</span> at any point is strictly smaller than the value of the function at that point itself, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \forall a \in \mathcal{S}: f(x) \geq f(a) + f'(a)(x-a) \,.
\end{align}\)</span></p>
<p>This inequality also holds for other values <span class="math notranslate nohighlight">\(g\)</span> instead of <span class="math notranslate nohighlight">\(f'(a)\)</span>, which are smaller than the true gradient <span class="math notranslate nohighlight">\(f'(a)\)</span> and since a gradient is never infinite, there have to be infinitely many of suitable <span class="math notranslate nohighlight">\(g\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \forall a \in \mathcal{S} \exists g \in \mathbb{R}: f(x) \geq f(a) + g(x-a) \,.
\end{align}\)</span></p>
<p>Such values <span class="math notranslate nohighlight">\(g\)</span> are called <em>subgradients</em> of the function <span class="math notranslate nohighlight">\(f\)</span> at position <span class="math notranslate nohighlight">\(a\)</span>. The set of all subgradients of <span class="math notranslate nohighlight">\(f\)</span> at position <span class="math notranslate nohighlight">\(a\)</span> is called the <em>subdifferential</em> <span class="math notranslate nohighlight">\(\partial_a f\)</span> of <span class="math notranslate nohighlight">\(f\)</span> at position <span class="math notranslate nohighlight">\(a\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \partial_a f(x) = \left\{ g\in \mathbb{R}: f(x) \geq f(a) + g(x-a) \right\}  \,.
\end{align}\)</span></p>
<p>Subdifferentials have the following useful properties (w.r.t a convex function <span class="math notranslate nohighlight">\(f\)</span> as defined above):</p>
<ul class="simple">
<li><p>The function <span class="math notranslate nohighlight">\(f\)</span> is differentiable at position <span class="math notranslate nohighlight">\(a\)</span> if and only if the set of subdifferentials at position <span class="math notranslate nohighlight">\(a\)</span> contains only a single slope value, i.e., if <span class="math notranslate nohighlight">\(\vert \partial_a f(x) \vert = 1\)</span>.</p></li>
<li><p>A point <span class="math notranslate nohighlight">\(a\)</span> is a global minimum of <span class="math notranslate nohighlight">\(f\)</span> if and only if <span class="math notranslate nohighlight">\(0 \in \partial_a f(x)\)</span>.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(k(x)\)</span> be another convex function like <span class="math notranslate nohighlight">\(f\)</span>. With the subdifferentials <span class="math notranslate nohighlight">\(\partial_a f(x), \partial_a k(x)\)</span> for some position <span class="math notranslate nohighlight">\(a\)</span>, the subdifferential of <span class="math notranslate nohighlight">\(f+k\)</span> for position <span class="math notranslate nohighlight">\(a\)</span> is then <span class="math notranslate nohighlight">\(\partial_a (f+k)(x) = \partial_a f(x) \oplus \partial_a k(x)\)</span> with <span class="math notranslate nohighlight">\(\oplus\)</span> denoting the so-called Minkowski sum (i.e., the set of all possible sums between all elements of the two input sets).</p></li>
</ul>
<p>We will now derive the subdifferential of <span class="math notranslate nohighlight">\(h(z) = \frac{\rho}{2}(v-z)^2 + \lambda \vert z \vert \)</span> (neglecting the position <span class="math notranslate nohighlight">\(a\)</span> for simplicity) and look for subgradients of <span class="math notranslate nohighlight">\(0\)</span>, which correspond to the sought minimum.</p>
<p>According to the third property introduced before, it is:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \partial h(z) = \partial \frac{\rho}{2}(v-z)^2 \oplus  \partial \lambda \vert z \vert \,.
\end{align}\)</span></p>
<p>Of course, the true gradient <span class="math notranslate nohighlight">\(f'(a)\)</span> of a function <span class="math notranslate nohighlight">\(f(x)\)</span> at position <span class="math notranslate nohighlight">\(a\)</span> is also a valid subgradient at position <span class="math notranslate nohighlight">\(a\)</span>, i.e.:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}\label{eq:hqs_z_1} 
  \partial h(z) = \lbrace \rho(-v+z) \rbrace \oplus  \partial \lambda \vert z \vert \,.   
\end{align}\)</span></p>
<p>The subdifferentials for the absolute value function are:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}\label{eq:hqs_z_2}
  \partial \lambda \vert z \vert = \begin{cases}
   &amp;-\lambda &amp;\text{ if } z &lt; 0\\
   &amp;[-\lambda, \lambda] &amp;\text{ if } z = 0\\
   &amp;\lambda &amp;\text{ if } z &gt; 0\\
  \end{cases} \,.
\end{align}\)</span></p>
<p>For <span class="math notranslate nohighlight">\(z\neq 0\)</span>, the absolute function is differentiable which is why its subdifferentials for those positions contains only one element (<span class="math notranslate nohighlight">\(\lambda\)</span> or <span class="math notranslate nohighlight">\(-\lambda\)</span> respectively). For <span class="math notranslate nohighlight">\(z=0\)</span> there infinitely many possible slope values inside the interval <span class="math notranslate nohighlight">\([-\lambda, \lambda]\)</span> (note: the value <span class="math notranslate nohighlight">\(0\)</span> is also contained in that interval, indicating that the global minimum must be at position <span class="math notranslate nohighlight">\(0\)</span>).</p>
<p>Combining \eqref{eq:hqs_z_1} and \eqref{eq:hqs_z_2} yields:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
  \partial h(z) =  \begin{cases}
    &amp;\rho(-v+z) - \lambda &amp;\text{ if } z &lt; 0\\
    &amp;[-\rho v-\lambda, -\rho v + \lambda] &amp;\text{ if } z = 0\\
    &amp;\rho(-v+z) + \lambda &amp;\text{ if } z &gt; 0
   \end{cases} \,.
\end{align}\)</span></p>
<p>We now equate all cases separately to <span class="math notranslate nohighlight">\(0\)</span>, solve for <span class="math notranslate nohighlight">\(z\)</span> and calculate the corresponding interval for <span class="math notranslate nohighlight">\(v\)</span> (which is the variable that we know, so we can use it to decide which case applies):</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \textbf{Case 1,  } z &lt; 0: \quad &amp;\rho(-v+z) - \lambda \overset{!}{=}0 \Leftrightarrow z \overset{!}{=} v + \frac{\lambda}{\rho} \\
  &amp;v + \frac{\lambda}{\rho}  \overset{!}{&lt;} 0 \Leftrightarrow v &lt; - \frac{\lambda}{\rho} \,.
\end{align}\)</span></p>
<p>For the second case, which is where the sought minimum is located, we want to always return <span class="math notranslate nohighlight">\(0\)</span> which is why we have to make sure that <span class="math notranslate nohighlight">\(0\)</span> is contained in the interval of possible slopes, i.e.,  <span class="math notranslate nohighlight">\(0 \in [-\rho v-\lambda, -\rho v + \lambda]\)</span>. Hence, it must hold</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
   -\rho v - \lambda \leq 0 &amp;\Leftrightarrow v \geq - \frac{\lambda }{\rho } \quad \text{and} \\
   0 \leq -\rho v + \lambda  &amp;\Leftrightarrow v \leq \frac{\lambda}{\rho} \,,
\end{align}\)</span></p>
<p>i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \textbf{Case 2,  } z &lt; 0: \quad \left| v \right| \leq \frac{\lambda }{\rho }\,.
\end{align}\)</span></p>
<p>The third case can be solved analogously to the first case:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \textbf{Case 3,  } z &gt; 0: \quad &amp;\rho(-v-z) + \lambda \overset{!}{=}0 \Leftrightarrow z \overset{!}{=} v - \frac{\lambda}{\rho} \\
  &amp; v - \frac{\lambda}{\rho}  \overset{!}{&gt;} 0 \Leftrightarrow v &gt; \frac{\lambda}{\rho} \,.
\end{align}\)</span></p>
<p><span class="math notranslate nohighlight">\(\square\)</span></p>
<p>The sought proximal operator is given by</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{\left\| \cdot \right\|_1, \rho } (\mathbf{v})_i =  \mathcal{S}_{\lambda / \rho} (v_i) = \begin{cases}
  v_i + \frac{\lambda}{\rho} &amp;\text{if } v_i &lt; - \frac{\lambda}{\rho}\\
  0 &amp;\text{if } \left| v_i \right| \leq \frac{\lambda }{\rho }\\
  v_i - \frac{\lambda}{\rho} &amp;\text{if } v_i &gt; \frac{\lambda}{\rho} 
\end{cases} \,,  
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(v_i\)</span> refering to the <span class="math notranslate nohighlight">\(i\)</span>-th element of the corresponding vector <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> (etc.).</p>
<p>The operator <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is also called the element-wise <em>soft thresholding operator</em>.</p>
</section>
<section id="visualization-of-soft-thresholding-operator">
<h5>Visualization of soft thresholding operator<a class="headerlink" href="#visualization-of-soft-thresholding-operator" title="Permalink to this headline">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">v</span><span class="p">,</span> <span class="n">rho</span><span class="p">,</span> <span class="n">lam</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lam</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="n">rho</span><span class="o">/</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="o">-</span><span class="n">z</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">s</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">kap</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;</span> <span class="n">kap</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">-</span><span class="n">kap</span>
    <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">kap</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">+</span><span class="n">kap</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">soft_thres_visu</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="mf">0.4</span>

    <span class="n">zs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">v</span><span class="p">,</span><span class="n">rho</span><span class="p">,</span><span class="n">lam</span><span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">]</span>

    <span class="n">vs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">lam</span><span class="o">/</span><span class="n">rho</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vs</span><span class="p">]</span>

    <span class="c1">#plt.subplots(1,2)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cur_s</span><span class="o">:=</span><span class="n">s</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">lam</span><span class="o">/</span><span class="n">rho</span><span class="p">),</span> <span class="n">y</span><span class="p">(</span><span class="n">cur_s</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">rho</span><span class="p">,</span> <span class="n">lam</span><span class="p">),</span> <span class="s1">&#39;bo&#39;</span> <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">vs</span><span class="p">,</span> <span class="n">ss</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">s</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">lam</span><span class="o">/</span><span class="n">rho</span><span class="p">),</span><span class="s1">&#39;bo&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">soft_thres_visu</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">v</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mf">3.0</span><span class="p">,</span><span class="nb">max</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/06_InverseProblemsInCompimg_135_0.png" src="_images/06_InverseProblemsInCompimg_135_0.png" />
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2ab96dceec2649868c3fd3d01b2e1e73"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(v)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="efficient-implementation-of-z-update-for-isotropic-tv-regularizer">
<h5>Efficient implementation of <span class="math notranslate nohighlight">\(z\)</span>-update for isotropic TV regularizer<a class="headerlink" href="#efficient-implementation-of-z-update-for-isotropic-tv-regularizer" title="Permalink to this headline">#</a></h5>
<p>For the isotropic case, the <span class="math notranslate nohighlight">\(l_2\)</span>-norm of the finite differences approximation of the horizontal and vertical image gradients is used as the regularizer instead of the <span class="math notranslate nohighlight">\(l_1\)</span>-norm, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \lambda \left\| \mathbf{z} \right\|_{2,1}  = \lambda \sum\limits^N_{i=1} \left\|  \begin{bmatrix} 
      (\mathbf{D}_x \mathbf{x})_i \\ (\mathbf{D}_y \mathbf{x})_i
   \end{bmatrix}  \right\|_2 = \lambda \sum\limits^N_{i=1} \sqrt{(\mathbf{D}_x \mathbf{x})^2_i + (\mathbf{D}_y \mathbf{x})^2_i } \,.
\end{align}\)</span></p>
<p>This expression is also called the <em>group lasso</em>.</p>
<p>Accordingly, the whole deconvolution problem for the isotropic TV regularizer is</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   &amp;\argmin{\mathbf{x}}\, \underbrace{\frac{1}{2} \left\| \mathbf{Cx-b} \right\|^2_2}_{=:f(\mathbf{x})} + \underbrace{\lambda \sum\limits^N_{i=1} \left\|  \begin{bmatrix} 
      z_i \\ z_{i+N}
   \end{bmatrix}   \right\|_2 }_{=:g(\mathbf{z})} \\
   &amp;\text{subject to } \mathbf{Dx-z=\mathbf{0}}\,.
\end{align}\)</span></p>
<p>Again, the vector <span class="math notranslate nohighlight">\(\mathbf{z} \in \mathbb{R}^{2\times N}\)</span> so that its first, respectively, second half can hold the image gradients in <span class="math notranslate nohighlight">\(x\)</span>-direction, respectively, in <span class="math notranslate nohighlight">\(y\)</span>-direction, i.e., <span class="math notranslate nohighlight">\(\mathbf{z} = \left[ \mathbf{D}_x \mathbf{x}\,\, \mathbf{D}_y \mathbf{x}   \right]\transp \)</span>.</p>
<p>As only the regularization term <span class="math notranslate nohighlight">\(g(\mathbf{z})\)</span> has changed, we only have to derive a corresponding <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-update rule, i.e., we have to find a solution for the proximal operator</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{z} \leftarrow \mathbf{prox}_{\left\| \cdot \right\|_{2,1},\rho } (\mathbf{v}) = \argmin{\mathbf{z}}\,\, \lambda \sum\limits^N_{i=1} \left\| \begin{bmatrix} 
    z_i \\ z_{i+N}
 \end{bmatrix}   \right\|_2  + \frac{\rho}{2} \left\| \mathbf{v-z} \right\| ^2_2, \quad \mathbf{v=Dx} \,.
\end{align}\)</span></p>
<p>Therefore, we again extract the term we have to minimize:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}\label{eq:hqs:iso:1}
   h(\mathbf{z}) := \lambda \left\| \mathbf{z} \right\|_2 + \frac{\rho}{2} \left\| \mathbf{v-z} \right\| ^2_2 \,.
\end{align}\)</span></p>
<p>We follow the approach of calculating the gradient of <span class="math notranslate nohighlight">\(h(\mathbf{z})\)</span>, equating it to <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> and solving for <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>.</p>
<p>The gradient of the second term with respect to <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> can be calculated straight forward:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \nabla_\mathbf{z} \frac{\rho}{2} \left\| \mathbf{v-z} \right\| ^2_2 = \rho (-\mathbf{v} + \mathbf{z}) \,.
\end{align}\)</span></p>
<p>The gradient of the Euclidean norm <span class="math notranslate nohighlight">\(\left\| \mathbf{x} \right\| _2\)</span> is</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \nabla_\mathbf{x} \left\| \mathbf{x} \right\|_2 = \frac{\mathbf{x}}{\left\| \mathbf{x} \right\|_2 }, \quad \text{for } \mathbf{x} \neq \mathbf{0} \,.
\end{align}\)</span></p>
<p>Hence, the gradient of the first term of \eqref{eq:hqs:iso:1} is</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \nabla_\mathbf{z} \lambda \left\| \mathbf{z} \right\| _2 = \lambda \frac{\mathbf{z}}{\left\| \mathbf{z} \right\|_2 } \quad \text{for } \mathbf{z} \neq \mathbf{0} \,.
\end{align}\)</span></p>
<p>So for <span class="math notranslate nohighlight">\(\mathbf{z} \neq \mathbf{0}\)</span>, we will find a <span class="math notranslate nohighlight">\(\hat{\mathbf{z}}\)</span> with <span class="math notranslate nohighlight">\(  \nabla_\mathbf{z} \lbrace h(\mathbf{z}) \rbrace (\hat{\mathbf{z}}) = \mathbf{0}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \lambda \frac{\mathbf{z}}{\left\| \mathbf{z} \right\|_2 } +  \rho (-\mathbf{v} + \mathbf{z}) &amp;\overset{!}{=} \mathbf{0} \\
  \mathbf{z}\left( \frac{\lambda}{\left\| \mathbf{z} \right\|_2 } + \rho \right) &amp;= \rho \mathbf{v} \,. \label{eq:hqs:iso:2}
\end{align}\)</span></p>
<p>We now apply the <span class="math notranslate nohighlight">\(l_2\)</span>-norm to both sides of the equation:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}  \label{eq:hqs:iso:3}
   \left| \frac{\lambda}{\left\| \mathbf{z} \right\|_2 }  + \rho\right| \cdot \left\| \mathbf{z} \right\|_2 = \left| \rho \right|  \left\| \mathbf{v} \right\|_2 \,.
\end{align}\)</span></p>
<p>The last step introduced two absolute values for each of which the two possible cases, .i.e, <span class="math notranslate nohighlight">\(&gt;0\)</span>, <span class="math notranslate nohighlight">\(&lt;0\)</span> have to be considered. Regarding the term <span class="math notranslate nohighlight">\(\left| \rho \right| \)</span> on the right side of the equation, only the positive case has to be considered since <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> by definition.</p>
<p>The first absolute term <span class="math notranslate nohighlight">\(\left| \frac{\lambda}{\left\| \mathbf{z} \right\|_2 }  + \rho\right|\)</span> is positive if</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \frac{\lambda}{\left\| \mathbf{z} \right\|_2 }  + \rho &amp;&gt; 0 \\  - \frac{\lambda}{\rho} &amp;&lt; \left\| \mathbf{z} \right\| _2 \,,
\end{align}\)</span></p>
<p>what always holds since due to <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> and <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> it follows <span class="math notranslate nohighlight">\(-\frac{\lambda}{\rho} &lt; 0\)</span> and since  <span class="math notranslate nohighlight">\(\left\| \mathbf{z} \right\| _2 &gt; 0\)</span> as <span class="math notranslate nohighlight">\(\left\| \cdot \right\| \geq 0\)</span> for any norm and <span class="math notranslate nohighlight">\(\mathbf{z} \neq \mathbf{0}\)</span> by definition of the considered case. Hence, the negative case is impossible.</p>
<p>We continue to solve \eqref{eq:hqs:iso:3} for <span class="math notranslate nohighlight">\(\left\| \mathbf{z} \right\| _2\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \left( \frac{\lambda}{\left\| \mathbf{z} \right\|_2 }  + \rho\right) \cdot \left\| \mathbf{z} \right\|_2 &amp;= \rho  \left\| \mathbf{v} \right\|_2  \\
  \lambda + \rho \left\| \mathbf{z} \right\| _2 &amp;= \rho \left\| \mathbf{v} \right\| _2 \\
  \left\| \mathbf{z} \right\| _2 &amp;= \frac{\rho \left\| \mathbf{v} \right\|_2 - \lambda  }{\rho} \,,
\end{align}\)</span></p>
<p>and now insert this expression for <span class="math notranslate nohighlight">\(\left\| \mathbf{z} \right\| _2\)</span> into \eqref{eq:hqs:iso:2} and solve for <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{z} \left( \lambda \cdot \frac{\rho }{\rho \left\| \mathbf{v} \right\|_2 - \lambda } + \rho  \right) &amp;= \rho \mathbf{v} \\
   \mathbf{z} \frac{\lambda + \rho  \left\| \mathbf{v} \right\|_2 - \lambda  }{\rho  \left\| \mathbf{v} \right\|_2 - \lambda  } &amp;= \mathbf{v}  \\
   \mathbf{z} &amp;= \mathbf{v} \cdot \frac{\rho  \left\| \mathbf{v} \right\|_2 - \lambda  }{\rho  \left\| \mathbf{v} \right\|_2 } \\
   \mathbf{z} &amp;= \mathbf{v} \cdot \left( 1 - \frac{\lambda }{\rho \left\| \mathbf{v} \right\|_2 } \right) \,.
\end{align}\)</span></p>
<p>In order to make sure that <span class="math notranslate nohighlight">\(\mathbf{z} \overset{!}{\neq} \mathbf{0}\)</span>, we have to check for which conditions <span class="math notranslate nohighlight">\(\left( 1 - \frac{\lambda }{\rho \left\| \mathbf{v} \right\|_2 } \right) &gt; 0\)</span> holds (we do not have to check for <span class="math notranslate nohighlight">\(&lt;0\)</span> as this is impossible as we showed when inspecting the absolute terms before):</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \left( 1 - \frac{\lambda }{\rho \left\| \mathbf{v} \right\|_2 } \right) &amp;&gt; 0 \\
  \left\| \mathbf{v} \right\|_2 &amp;&gt; \frac{\lambda }{\rho } \,.
\end{align}\)</span></p>
<p>For <span class="math notranslate nohighlight">\(\mathbf{z} = \mathbf{0}\)</span>, there is no well-defined gradient for <span class="math notranslate nohighlight">\(\left\| \mathbf{z} \right\|_2\)</span>, so we make use of the concept of subdifferentials again and derive the subdifferential of <span class="math notranslate nohighlight">\(h(\mathbf{z})\)</span> with respect to position <span class="math notranslate nohighlight">\(\mathbf{z} = \mathbf{0}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  h(\mathbf{z}) &amp;= \lambda \left\| \mathbf{z} \right\|_2 + \frac{\rho}{2} \left\| \mathbf{v-z} \right\| ^2_2 \\
  \frac{h(\mathbf{z})}{\rho} &amp;= \frac{\lambda}{\rho } \left\| \mathbf{z} \right\|_2 + \frac{1}{2} \left\| \mathbf{v-z} \right\|^2_2  \\
  \partial_\mathbf{0} \frac{h(\mathbf{z})}{\rho} &amp;= \partial_\mathbf{0} \frac{\lambda}{\rho } \left\| \mathbf{z} \right\|_2 \oplus  \partial_\mathbf{0}\frac{1}{2} \left\| \mathbf{v-z} \right\|^2_2 \,.
\end{align}\)</span></p>
<p>As before, we can replace the second subdifferential on the right side of the equation with the true gradient:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \partial_\mathbf{0} \frac{h(\mathbf{z})}{\rho} &amp;= \partial_\mathbf{0} \frac{\lambda}{\rho } \left\| \mathbf{z} \right\|_2 \oplus  \lbrace - \mathbf{v} \rbrace \,.
\end{align}\)</span></p>
<p>For the first term, i.e., <span class="math notranslate nohighlight">\(\partial_\mathbf{0}\frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2\)</span>, we employ the definition of subdifferentials:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \partial_\mathbf{0}\frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 &amp;= \left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 \geq \frac{\lambda}{\rho} \left\| \mathbf{0} \right\|_2 + \left\langle \mathbf{g} , \mathbf{z} - \mathbf{0}\right\rangle  \right\} \\
  \partial_\mathbf{0}\frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 &amp;= \left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 \geq \left\langle \mathbf{g} , \mathbf{z}\right\rangle  \right\} \,.
\end{align}\)</span></p>
<p>By means of the Cauchy-Schwarz inequality, i.e., <span class="math notranslate nohighlight">\(\left\langle \mathbf{g}, \mathbf{z} \right\rangle \leq \left\| \mathbf{g} \right\| \cdot \left\| \mathbf{z} \right\| \)</span>, we can further simplify the derivation:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \partial_\mathbf{0}\frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 &amp;= \left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 \geq \left\langle \mathbf{g} , \mathbf{z}\right\rangle  \right\} \\
  &amp;= \left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho} \left\| \mathbf{z} \right\|_2 \geq \left\| \mathbf{g} \right\|_2 \cdot \left\| \mathbf{z} \right\|_2     \right\} \\
  &amp;= \left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho}  \geq \left\| \mathbf{g} \right\|_2      \right\} \,.
\end{align}\)</span></p>
<p>The resulting combined expression for the subdifferential of <span class="math notranslate nohighlight">\(\frac{h(\mathbf{z})}{\rho} \)</span> is:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \partial_\mathbf{0}\frac{h(\mathbf{z})}{\rho} = \left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho}  \geq \left\| \mathbf{g} \right\|_2      \right\} \oplus \lbrace -\mathbf{v} \rbrace \,.
\end{align}\)</span></p>
<p>For <span class="math notranslate nohighlight">\(\mathbf{z} = \mathbf{0}\)</span> we want to return <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> if possible since that would correspond to the sought minimum. A subgradient <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> is contained in <span class="math notranslate nohighlight">\(\partial_\mathbf{0}\frac{h(\mathbf{z})}{\rho}\)</span> if the first subdifferential <span class="math notranslate nohighlight">\(\left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho}  \geq \left\| \mathbf{g} \right\|_2      \right\}\)</span> contains a vector <span class="math notranslate nohighlight">\(\mathbf{g}\)</span> with <span class="math notranslate nohighlight">\(\mathbf{g} = \mathbf{v}\)</span> because then the Minkowski sum <span class="math notranslate nohighlight">\(\left\{ \mathbf{g} \in \mathbb{R}^{2N} : \frac{\lambda}{\rho}  \geq \left\| \mathbf{g} \right\|_2      \right\} \oplus \lbrace -\mathbf{v} \rbrace\)</span> would contain <span class="math notranslate nohighlight">\(\mathbf{0}\)</span>. This is only possible for any vectors <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> with <span class="math notranslate nohighlight">\(\left\| \mathbf{v} \right\|_2 \leq \frac{\lambda}{\rho}  \)</span>.</p>
<p>With these results, the final <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-update rule is given by:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \begin{bmatrix} 
     z_i \\ z_{i+N}
  \end{bmatrix} \leftarrow \mathcal{S}_{\lambda / \rho} \left(\mathbf{v}':= \begin{bmatrix} 
     v_i \\ v_{i+N}
  \end{bmatrix} \right) =  \begin{cases} 
    \mathbf{v}' \cdot \left( 1 - \frac{\lambda }{\rho \left\| \mathbf{v}' \right\|_2 } \right) &amp;\text{if } \left\| \mathbf{v}' \right\| _2 &gt; \frac{\lambda}{\rho} \\
    \mathbf{0} &amp;\text{if } \left\| \mathbf{v}' \right\| _2 \leq \frac{\lambda}{\rho}
  \end{cases}
   \,.
\end{align}\)</span></p>
<p>This expression (i.e., <span class="math notranslate nohighlight">\(\mathcal{S}_{\lambda / \rho}\)</span>) is also known as the vector soft-thresholding operator.</p>
</section>
<section id="efficient-update-of-mathbf-z-in-general-case">
<h5>Efficient update of <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> in general case<a class="headerlink" href="#efficient-update-of-mathbf-z-in-general-case" title="Permalink to this headline">#</a></h5>
<p>In the general case, i.e., with <span class="math notranslate nohighlight">\(\mathbf{D} = \mathbf{I}\)</span>, we want to solve</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{z} \leftarrow &amp;\argmin{\mathbf{z}}\, g(\mathbf{z}) + \frac{\rho}{2} \left\| \mathbf{x} - \mathbf{z} \right\| ^2_2 \,, \\
   &amp;\argmin{\mathbf{z}}\, \lambda \Psi(\mathbf{z}) + \frac{\rho}{2} \left\| \mathbf{x-z} \right\|^2_2 \,, \\
   &amp;\argmin{\mathbf{z}}\,  \Psi(\mathbf{z}) + \frac{\rho}{2\lambda} \left\| \mathbf{x-z} \right\| ^2_2 \,.
\end{align}\)</span></p>
<p>For <span class="math notranslate nohighlight">\(\frac{\lambda}{\rho} = \sigma^2\)</span>, the last equation represents a denoising problem for zero-mean Gaussian noise with variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> as we have seen earlier:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \argmin{\mathbf{s}}\, \Gamma (\mathbf{s}) + \frac{1}{2\sigma^2}\left\| \mathbf{g} - \mathbf{s} \right\|^2_2   \,.
\end{align}\)</span></p>
<p>This means that we can use any Gaussian denoiser <span class="math notranslate nohighlight">\(\mathcal{D}: \mathbb{R} ^N \rightarrow  \mathbb{R} ^N\)</span> as our proximal operator for the <span class="math notranslate nohighlight">\(z\)</span>-update, e.g., the denoising CNN from the last chapter.</p>
<p><span class="math notranslate nohighlight">\(\rightarrow\)</span> Any Gaussian denoiser suitable for a noise variance of <span class="math notranslate nohighlight">\(\sigma^2\)</span> can be used as a general image prior:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{z} \leftarrow \mathrm{prox}_{\mathcal{D}, \rho} (\mathbf{x}) =\mathcal{D}\left( \mathbf{x}, \sigma^2 = \frac{\lambda}{\rho}  \right)  \,.
\end{align}\)</span></p>
</section>
</section>
</section>
<section id="hqs-for-general-linear-inverse-problems">
<h3>HQS for general linear inverse problems<a class="headerlink" href="#hqs-for-general-linear-inverse-problems" title="Permalink to this headline">#</a></h3>
<p>HQS can also be applied to linear inverse problems, i.e., <span class="math notranslate nohighlight">\(\mathbf{b} = \mathbf{Ax} + \mathbf{n}\)</span>.</p>
<p>Depending on the prior, we can use the <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-updates already derived for the deconvolution problem (i.e., total variation or a general Gaussian denoiser).</p>
<p>However, we have to look again at the <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>-update, as the matrix-vector multiplication <span class="math notranslate nohighlight">\(\mathbf{Ax}\)</span> does not (necessarily) encode a convolution anymore.</p>
<section id="derivation-of-mathbf-x-update-for-hqs-for-general-linear-inverse-problems">
<h4>Derivation of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>-update for HQS for general linear inverse problems<a class="headerlink" href="#derivation-of-mathbf-x-update-for-hqs-for-general-linear-inverse-problems" title="Permalink to this headline">#</a></h4>
<p>For the <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>-update, we use the following solution:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{x} \leftarrow \mathrm{prox}_{\left\| \cdot \right\| _2, \rho} (\mathbf{v}) &amp;= \argmin{\mathbf{x}}\, \frac{1}{2} \left\| \mathbf{Ax-b} \right\| ^2_2 + \frac{\rho}{2}\left\| \mathbf{Dx-z} \right\| ^2_2  \\
   &amp;= \left( \underbrace{\mathbf{A}\transp \mathbf{A} + \rho  \mathbf{D}\transp D}_{\tilde{\mathbf{A}}} \right)^{-1}  \left( \underbrace{\mathbf{A}\transp \mathbf{b} + \rho \mathbf{D}\transp \mathbf{z}}_{\tilde{\mathbf{b}}} \right) \,,
\end{align}\)</span></p>
<p>whose derivation is equivalent to the deconvolution problem.</p>
<p>Unfortunately, for the case of a general matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>, there is no elegant closed-form solution as for the case of deconvolution.</p>
<p><span class="math notranslate nohighlight">\(\rightarrow\)</span> Use an iterative solver to solve <span class="math notranslate nohighlight">\(\tilde{\mathbf{A}} \mathbf{x} = \tilde{\mathbf{b}}\)</span> for <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Since <span class="math notranslate nohighlight">\(\tilde{\mathbf{A}}\)</span> is symmetric and positive semi-definite, the so-called <em>conjugate gradient</em> method is a good choice.</p>
</section>
</section>
<section id="problems-of-hqs">
<h3>Problems of HQS<a class="headerlink" href="#problems-of-hqs" title="Permalink to this headline">#</a></h3>
<p>The HQS method works well for inverse problems where the number of available measurements <span class="math notranslate nohighlight">\(M\)</span> is in the range of the number of unknowns <span class="math notranslate nohighlight">\(N\)</span>. For the case of deconvolution, it is <span class="math notranslate nohighlight">\(M=N\)</span> and hence HQS represents a suitable choice.</p>
<p>However, for severely under-determined problems, the penalty <span class="math notranslate nohighlight">\(\frac{\rho}{2}\left\| \mathbf{Dx-z} \right\|^2_2 \)</span> linking data fidelity and the prior terms can be too weak so that the algorithm does not converge well.</p>
<p>We will now get to know a method that mitigates that problem.</p>
</section>
</section>
<section id="alternating-direction-method-of-multipliers-admm">
<h2>Alternating direction method of multipliers (ADMM)<a class="headerlink" href="#alternating-direction-method-of-multipliers-admm" title="Permalink to this headline">#</a></h2>
<p>Similar to the HQS approach, the so-called <em>alternating direction method of multipliers (ADMM)</em> splits the objective function</p>
<p><span class="math notranslate nohighlight">\(
\begin{align} 
  \argmin{\mathbf{x}}\quad &amp;\underbrace{\frac{1}{2}\left\| \mathbf{Ax-b} \right\|^2_2 }_{=:f(\mathbf{x})} + \underbrace{\lambda \Psi (\mathbf{z})}_{=:g(\mathbf{z})} \\
  \text{subject to}\quad &amp;\mathbf{Dx-z} = \mathbf{0} \,.
\end{align}
\)</span></p>
<p>into multiple terms and optimizes it in an alternating fashion.</p>
<p>But instead of transforming the constraint <span class="math notranslate nohighlight">\(\mathbf{Dx-z} = \mathbf{0}\)</span> into a penalty term, it employs the so-called <em>augmented Lagrangian</em> of the objective function:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   L^\mathrm{(ADMM)}_\rho (\mathbf{x,z,y}) = f(\mathbf{x}) + g(\mathbf{z}) + \mathbf{y}\transp \left( \mathbf{Dx-z} \right) + \frac{\rho}{2} \left\| \mathbf{Dx-z} \right\| ^2_2 \,,
\end{align}\)</span></p>
<p>with the Lagrange multiplier <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>.</p>
<p>The so-called <em>scaled form</em> of the augmented Lagrangian is given by</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  L^\mathrm{(ADMM)}_\rho (\mathbf{x,z,u}) = f(\mathbf{x}) + g(\mathbf{z}) + \frac{\rho}{2} \left\| \mathbf{Dx-z+u} \right\|^2_2 - \frac{\rho}{2} \left\| \mathbf{u} \right\| ^2_2  \,,
\end{align}\)</span></p>
<p>with the scaled Lagrangian multiplier <span class="math notranslate nohighlight">\(\mathbf{u} = \frac{1}{\rho} \mathbf{y}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The augmented Lagrangian and its scaled form are identical, i.e., just mathematical reformulations that come in handy for further steps.</p>
</div>
<p>The update rules for the variables <span class="math notranslate nohighlight">\(\mathbf{x,z,u}\)</span> are given by</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathbf{x} &amp;\leftarrow \mathrm{prox}_{\left\| \cdot \right\|_2, \rho } (\mathbf{v}) =\argmin{\mathbf{x}}\, L^{\mathrm{(ADMM)}}_\rho (\mathbf{x,z,u}) = \argmin{\mathbf{x}}\, \frac{1}{2} \left\| \mathbf{Ax-b} \right\|^2_2 + \frac{\rho}{2} \left\| \mathbf{Dx-z+u} \right\|^2_2 \,, \\
   \mathbf{z} &amp;\leftarrow  \mathrm{prox}_{\Psi, \rho}(\mathbf{v}) = \argmin{\mathbf{z}}\, L^{\mathrm{(ADMM)}}_\rho (\mathbf{x,z,u}) = \argmin{\mathbf{z}}\, \lambda \Psi (\mathbf{z}) + \frac{\rho}{2} \left\| \mathbf{Dx-z+u} \right\|^2_2 \,, \\
   \mathbf{u} &amp;\leftarrow \mathbf{u} + \mathbf{Dx-z}
\end{align}\)</span></p>
<p>For the <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>- and <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-updates we can again use proximal operators. The <span class="math notranslate nohighlight">\(\mathbf{u}\)</span>-update is a straightforward sum of vectors (for its derivation see the article <a class="reference external" href="https://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf">Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers</a> by Stephen Boyd et al.).</p>
<section id="the-mathbf-x-update">
<h3>The <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>-update:<a class="headerlink" href="#the-mathbf-x-update" title="Permalink to this headline">#</a></h3>
<p>The <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>-update within ADMM is quite similar to that of HQS, we just have to adequately account for <span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{\left\| \cdot \right\|_2, \rho } (\mathbf{\mathbf{z-u}}) = \left( \underbrace{\mathbf{A}\transp \mathbf{A} + \rho  \mathbf{D}\transp D}_{\tilde{\mathbf{A}}} \right)^{-1}  \left( \underbrace{\mathbf{A}\transp \mathbf{b} + \rho \mathbf{D}\transp (\mathbf{z-u})}_{\tilde{\mathbf{b}}} \right) \,.
\end{align}\)</span></p>
</section>
<section id="the-mathbf-z-update">
<h3>The <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-update:<a class="headerlink" href="#the-mathbf-z-update" title="Permalink to this headline">#</a></h3>
<p>For the <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-update, we can rely on the same proximal operators as HQS.</p>
<p>In the case of the TV regularizer, the proximal operator is the element-wise soft thresholding operator:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
  \mathrm{prox}_{\left\| \cdot \right\|_1, \rho } (\mathbf{v}) = \argmin{\mathbf{z}}\, \lambda \left\| \mathbf{z} \right\|_1 + \frac{\rho}{2}\left\| \mathbf{v-z} \right\|^2_2 = \mathcal{S}_{\lambda / \rho} (\mathbf{v})\,.  
\end{align}\)</span></p>
<p>Since for HQS it is <span class="math notranslate nohighlight">\(\mathbf{v} = \mathbf{Dx}\)</span>, we again have to account for <span class="math notranslate nohighlight">\(\mathbf{u}\)</span> as <span class="math notranslate nohighlight">\(\mathbf{v} = \mathbf{Dx} + \mathbf{u}\)</span>.</p>
<p>In the general case, i.e., for <span class="math notranslate nohighlight">\(\mathbf{D=I}\)</span>, we can use any Gaussian denoiser <span class="math notranslate nohighlight">\(\mathcal{D}: \mathbb{R} ^N \rightarrow \mathbb{R}^N\)</span> as a regularizer leading to the following <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>-update:</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \mathrm{prox}_{\mathcal{D}, \rho} (\mathbf{v}) = \mathcal{D} \left( \mathbf{v}, \sigma^2=\frac{\lambda }{\rho} \right) \,,
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(\mathbf{v = x + u}\)</span>.</p>
</section>
</section>
<section id="deep-snr-estimation-for-wiener-filtering">
<h2>Deep SNR-estimation for Wiener filtering<a class="headerlink" href="#deep-snr-estimation-for-wiener-filtering" title="Permalink to this headline">#</a></h2>
<p>As elaborated before, one main drawback of the Wiener filter is the necessity for the user to correctly estimate the signal-to-noise ratio</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   SNR\,(\mathbf{f}) = \frac{S_{ss}(\mathbf{f})}{S_{nn}(\mathbf{f})} \,, 
\end{align}\)</span></p>
<p>with <span class="math notranslate nohighlight">\(S_{ss}(\mathbf{f}), S_{nn}(\mathbf{f})\)</span> denoting the power spectral density of the signal component, respectively, of the noise component.</p>
<p>In the unusual case when one has access to <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(n\)</span>, it is possible to calculate (not unbiased) estimates of <span class="math notranslate nohighlight">\(S_{ss}(\mathbf{f}), S_{nn}(\mathbf{f})\)</span> via</p>
<p><span class="math notranslate nohighlight">\(\begin{align} 
   \hat{S}_{ss}(\mathbf{f}) &amp;= \vert \F \left\{ s(\mathbf{x}) \right\}   \vert^2 \, , \\
   \hat{S}_{nn}(\mathbf{f}) &amp;= \vert \F \left\{ n(\mathbf{x}) \right\}   \vert^2 \,.
\end{align}\)</span></p>
<p>Fortunately we could show that a neural network <span class="math notranslate nohighlight">\(\phi\)</span> can be trained to precisely estimate the signal-to-noise ratio based on the observed image <span class="math notranslate nohighlight">\(g\)</span> only.</p>
<p>To make the task easier for the neural network, we trained it to consume estimates of the power spectral density of <span class="math notranslate nohighlight">\(g\)</span> to estimate the signal-to-noise ratio. By this means, both input and output have spatial frequencies as variables.</p>
<p>Directly training <span class="math notranslate nohighlight">\(\phi\)</span> with pairs of <span class="math notranslate nohighlight">\(\left( \hat{S}_{gg}, \widehat{SNR} \right)\)</span> would lead to slow or even no convergence of the training due to the high dynamic range of the squared magnitude spectra of the Fourier transforms.</p>
<p>Hence, we train <span class="math notranslate nohighlight">\(\phi\)</span> with pairs <span class="math notranslate nohighlight">\(\left(  \log \hat{S}_{gg}, \log \widehat{SNR} \right)\)</span>,i.e., so that <span class="math notranslate nohighlight">\(\phi\left( \log \hat{S}_{gg}(\mathbf{f})\right)= \log \widehat{SNR}\,(\mathbf{f})\)</span>.</p>
<p>The following figure visualizes the training procedure:</p>
<img src="figures/6/dw_training.svg" style="max-height:40vh"><p>To apply the method for image reconstruction the following steps are performed:</p>
<ul class="simple">
<li><p>Calculate <span class="math notranslate nohighlight">\(\hat{S}_{gg}(\mathbf{f}) = \left| \F \left\{ g(\mathbf{x}) \right\}  \right|^2 \)</span> for the observed image <span class="math notranslate nohighlight">\(g\)</span>,</p></li>
<li><p>use <span class="math notranslate nohighlight">\(\phi\)</span> to estimate the signal-to-noise ratio via <span class="math notranslate nohighlight">\(\widehat{SNR}\,(\mathbf{f}) \leftarrow \phi(\hat{S}_{gg}(\mathbf{f})) \)</span>,</p></li>
<li><p>estimate the undistorted image <span class="math notranslate nohighlight">\(\hat{s}\)</span> by applying the Wiener filter to <span class="math notranslate nohighlight">\(g\)</span> and by using the estimated <span class="math notranslate nohighlight">\(\widehat{SNR}\)</span>.</p></li>
</ul>
<section id="example-wiener-filter-reconstruction-results-with-deep-snr-estimation">
<h3>Example Wiener filter reconstruction results with deep SNR-estimation<a class="headerlink" href="#example-wiener-filter-reconstruction-results-with-deep-snr-estimation" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">showFig</span><span class="p">(</span><span class="s1">&#39;figures/6/dw_ex_&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;.png&#39;</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">i</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="p">(</span><span class="n">min_i</span><span class="o">:=</span><span class="mi">1</span><span class="p">),</span><span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="n">max_i</span><span class="o">:=</span><span class="mi">8</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span> <span class="k">if</span> <span class="n">book</span> <span class="k">else</span> <span class="n">min_i</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "e2becfdd3db54b9b99153c1b9a6bc1cc"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.&lt;lambda&gt;(i)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="quantitative-results">
<h3>Quantitative results<a class="headerlink" href="#quantitative-results" title="Permalink to this headline">#</a></h3>
<p>To quantify the deconvolution performance of the proposed method, the <a class="reference external" href="http://ieeexplore.ieee.org/document/6528301/">dataset published by Libin Sun et al.</a> has been employed.</p>
<p>The reconstruction results are numerically compared against the ground truths by means of the so-called <em>peak signal-to-noise ratio PSNR</em> (logarithmic scale, no maximum value) and the so-called <em>structural similarity index SSIM</em> (mimics the human perception of image similarity, maximum value of 1.0 for full equality).</p>
<table>
<thead>
  <tr>
      <th style="text-align:left">Method</th>
      <th>PSNR</th>
      <th>SSIM</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td style="text-align:left">Fourier Deconvolution Network (2017)</td>
    <td>32.67</td>
    <td>0.8887</td>
  </tr>
  <tr>
    <td style="text-align:left">Cascade of Shrinkage Fields (2014)</td>
    <td>32.21</td>
    <td>0.8622</td>
  </tr>
  <tr>
    <td style="text-align:left">Expected Patch Log Likelihood (2011)</td>
    <td>32.48</td>
    <td>0.8815</td>
  </tr>
  <tr>
    <td style="text-align:left">Wiener meets Deep Learning (2020)</td>
    <td>34.05</td>
    <td>0.9225</td>
  </tr>
  <tr>
      <td style="text-align:left"><b>Wiener filter with deep SNR-estimation</b></td>
      <td><b>40.83 $\pm$ 1.8</b></td>
      <td><b>0.97 $\pm$ 0.01</b></td>
  </tr>
  <tr >
    <td colspan="100%"></td>
  </tr>
  <tr>
    <td style="text-align:left">Wiener filter with ground truth SNR</td>
    <td>42.31 $\pm$ 1.7</td>
    <td>0.98 $\pm$ 0.01</td>
  </tr>
  <tr>
    <td style="text-align:left">Wiener filter with heuristic $\mathbf{f}^2$</td>
    <td>32.23 $\pm$ 2.3</td>
    <td>0.81 $\pm$ 0.1</td>
  </tr>
</tbody>
</table></section>
</section>
<section id="unrolled-optimization">
<h2>Unrolled optimization<a class="headerlink" href="#unrolled-optimization" title="Permalink to this headline">#</a></h2>
<p>For traditional HQS and ADMM implementations, the values of the hyperparameters <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(\rho\)</span> are chosen once and remain fix while performing the optimization.</p>
<p>Although this works well in many cases, it can be beneficial to set the number <span class="math notranslate nohighlight">\(i\)</span> of iterations to a fixed value and replicate the parameter update routines <span class="math notranslate nohighlight">\(i\)</span> times, each with individual hyperparameters <span class="math notranslate nohighlight">\(\lambda_i, \rho_i\)</span>.</p>
<p>The resulting structure can be interpreted and dealt with like a neural network (especially if some deep denoising prior is included). Then, the hyperparameters <span class="math notranslate nohighlight">\(\lambda_i, \rho_i\)</span> and the parameters of a potentially included neural network can be learned (i.e., optimized) in an end-to-end fashion in a joint training procedure.</p>
<p>Advantages of unrolled optimization:</p>
<ul class="simple">
<li><p>Whole method becomes end-to-end differentiable.</p></li>
<li><p>Hyperparameters <span class="math notranslate nohighlight">\(\lambda_i, \rho_i\)</span> can be learned and optimized allowing to realize a hyperparameter-schedule (e.g., increasing the <span class="math notranslate nohighlight">\(\rho_i\)</span> over time).</p></li>
<li><p>The denoising neural network can adapt to the actual matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> or the convolution kernel (even with respect to every individual iteration).</p></li>
<li><p>Skip connections from earlier iterations to later iterations can be realized.</p></li>
</ul>
</section>
</section>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"b8d8bc90c519409f8c6ab6d33de22699": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9dfa71f66559402eb322beb514f26d78": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "9acf82c5cad1431daf8b532447833d26": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "i", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_b8d8bc90c519409f8c6ab6d33de22699", "max": 6, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_9dfa71f66559402eb322beb514f26d78", "value": 6}}, "22df75bda00c4404b77194daf1fac77c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "abc8e1ea1a2f45f7b8a759170da0ac76": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_9acf82c5cad1431daf8b532447833d26", "IPY_MODEL_a073c8ea7daa4e4db71b07bf30ed5816"], "layout": "IPY_MODEL_22df75bda00c4404b77194daf1fac77c"}}, "bf201b9bea5d4948bc28601f90738236": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a073c8ea7daa4e4db71b07bf30ed5816": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_bf201b9bea5d4948bc28601f90738236", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<img src=\"figures/6/inv_filter_res_6.svg\" style=\"max-height:50vh\"/>"}}]}}, "6ad2dce96fbd4b41999ee848608a5f92": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b934456e0030481d8f914c37ea3c8c8d": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "1d28bf8c65214d83be18419e22d7cb84": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "i", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_6ad2dce96fbd4b41999ee848608a5f92", "max": 6, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_b934456e0030481d8f914c37ea3c8c8d", "value": 6}}, "f7f092d71e8d4821ba4345e3fe309a68": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9a61fa7dace041269b9ff8dbe3c7c544": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_1d28bf8c65214d83be18419e22d7cb84", "IPY_MODEL_f23140661ddd414bbc56294385ca63df"], "layout": "IPY_MODEL_f7f092d71e8d4821ba4345e3fe309a68"}}, "2b3298d6236147d3889c7dd8fa7096b5": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f23140661ddd414bbc56294385ca63df": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_2b3298d6236147d3889c7dd8fa7096b5", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<img src=\"figures/6/wiener_filter_res_6.svg\" style=\"max-height:50vh\"/>"}}]}}, "eb3ff1606de54081bcf8b141eceea70a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "54111d9775ca4e24b4930329c2a3f429": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "d18e192eebbc4ae7bf9ccb94f2d0de2d": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "v", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_eb3ff1606de54081bcf8b141eceea70a", "max": 3.0, "min": -3.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.2, "style": "IPY_MODEL_54111d9775ca4e24b4930329c2a3f429", "value": 0.0}}, "136649357b0a4521906bac096f88a7d7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2ab96dceec2649868c3fd3d01b2e1e73": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_d18e192eebbc4ae7bf9ccb94f2d0de2d", "IPY_MODEL_9462a6b87f5b4bafb589258cdef53ffa"], "layout": "IPY_MODEL_136649357b0a4521906bac096f88a7d7"}}, "e5c890593d494887975453fce6a547b8": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9462a6b87f5b4bafb589258cdef53ffa": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_e5c890593d494887975453fce6a547b8", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {"needs_background": "light"}, "data": {"text/plain": "<Figure size 432x288 with 2 Axes>", "image/png": "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\n"}}]}}, "1a57f828241d40609a58cc77338fb1d7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6574d1948d634da1b5be18ab3083432c": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "dc99382f0014441982a4cb2ea1d34d08": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "i", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_1a57f828241d40609a58cc77338fb1d7", "max": 8, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_6574d1948d634da1b5be18ab3083432c", "value": 6}}, "9c1b2f3f9b6345b68069726e06e62c06": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e2becfdd3db54b9b99153c1b9a6bc1cc": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_dc99382f0014441982a4cb2ea1d34d08", "IPY_MODEL_578d4bd47d074b3195034670fc9fb4df"], "layout": "IPY_MODEL_9c1b2f3f9b6345b68069726e06e62c06"}}, "185e499f790440b8937a7e22c45a3ffd": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "578d4bd47d074b3195034670fc9fb4df": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_185e499f790440b8937a7e22c45a3ffd", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<img src=\"figures/6/dw_ex_6.png\" style=\"max-height:50vh\"/>"}}]}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "compimg"
        },
        kernelOptions: {
            kernelName: "compimg",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'compimg'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="05_NeuralNetworksForCompImg.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Neural Networks for Computational Imaging</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Dr.-Ing. Johannes Meyer<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>